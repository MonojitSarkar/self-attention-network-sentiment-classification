{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport torch.optim as optim\nfrom IPython.core.debugger import set_trace\nfrom collections import Counter\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator, GloVe\nfrom torchtext.data.utils import get_tokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-13T08:20:57.608015Z","iopub.execute_input":"2024-04-13T08:20:57.608700Z","iopub.status.idle":"2024-04-13T08:21:05.069054Z","shell.execute_reply.started":"2024-04-13T08:20:57.608674Z","shell.execute_reply":"2024-04-13T08:21:05.068239Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\n\n# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")\n      \nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:21:05.070490Z","iopub.execute_input":"2024-04-13T08:21:05.070967Z","iopub.status.idle":"2024-04-13T08:21:05.107343Z","shell.execute_reply.started":"2024-04-13T08:21:05.070937Z","shell.execute_reply":"2024-04-13T08:21:05.106573Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"GPU is available\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"base_csv = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'\ndf = pd.read_csv(base_csv)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:21:05.108527Z","iopub.execute_input":"2024-04-13T08:21:05.108824Z","iopub.status.idle":"2024-04-13T08:21:06.863835Z","shell.execute_reply.started":"2024-04-13T08:21:05.108801Z","shell.execute_reply":"2024-04-13T08:21:06.862925Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = list(set(stopwords.words('english')))\n\ndef preprocess_string(s):\n    s = s.lower()\n    s = ' '.join([word for word in s.split() if word not in stop_words])\n    # replace <br /><br /> with nothing\n    s = re.sub('<[^>]+>', '', s)\n    # Remove all non-word characters (everything except numbers and letters)\n    s = re.sub(r\"[^\\w\\s]\", ' ', s)\n    # Replace all runs of whitespaces with no space\n    s = re.sub(r\"\\s+\", ' ', s)\n    # replace digits with no space\n    s = re.sub(r\"\\d\", '', s)\n    \n    # remove single characters\n    s = ' '.join(list(filter(lambda x: len(x)!=1, s.split())))\n    \n\n    return s","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:21:06.865867Z","iopub.execute_input":"2024-04-13T08:21:06.866149Z","iopub.status.idle":"2024-04-13T08:21:06.876881Z","shell.execute_reply.started":"2024-04-13T08:21:06.866125Z","shell.execute_reply":"2024-04-13T08:21:06.876034Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.loc[:, 'review_2'] = df.loc[:, 'review'].apply(preprocess_string)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:21:06.877911Z","iopub.execute_input":"2024-04-13T08:21:06.878169Z","iopub.status.idle":"2024-04-13T08:21:36.595786Z","shell.execute_reply.started":"2024-04-13T08:21:06.878146Z","shell.execute_reply":"2024-04-13T08:21:36.594848Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  \\\n0  One of the other reviewers has mentioned that ...  positive   \n1  A wonderful little production. <br /><br />The...  positive   \n2  I thought this was a wonderful way to spend ti...  positive   \n3  Basically there's a family where a little boy ...  negative   \n4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n\n                                            review_2  \n0  one reviewers mentioned watching oz episode ho...  \n1  wonderful little production the filming techni...  \n2  thought wonderful way spend time hot summer we...  \n3  basically there family little boy jake thinks ...  \n4  petter mattei love time money visually stunnin...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>review_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>one reviewers mentioned watching oz episode ho...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>wonderful little production the filming techni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>thought wonderful way spend time hot summer we...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>basically there family little boy jake thinks ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>petter mattei love time money visually stunnin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X,y = df['review_2'].values,df['sentiment'].values\nx_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y, test_size=0.1)\nprint(f'shape of train data is {x_train.shape}')\nprint(f'shape of test data is {x_test.shape}')\ny_train = [1 if label =='positive' else 0 for label in y_train]  \ny_test = [1 if label =='positive' else 0 for label in y_test] ","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:21:36.597377Z","iopub.execute_input":"2024-04-13T08:21:36.598108Z","iopub.status.idle":"2024-04-13T08:21:36.684978Z","shell.execute_reply.started":"2024-04-13T08:21:36.598068Z","shell.execute_reply":"2024-04-13T08:21:36.684055Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"shape of train data is (45000,)\nshape of test data is (5000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"glove_embed_dim = 50\nglobe = GloVe(name='6B', dim=glove_embed_dim)\nglove_weights = torch.load(f\".vector_cache/glove.6B.{glove_embed_dim}d.txt.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:25.399269Z","iopub.execute_input":"2024-04-13T08:39:25.399935Z","iopub.status.idle":"2024-04-13T08:39:43.669990Z","shell.execute_reply.started":"2024-04-13T08:39:25.399903Z","shell.execute_reply":"2024-04-13T08:39:43.668976Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"100%|█████████▉| 399999/400000 [00:16<00:00, 24607.45it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"glove_vocab = glove_weights[0]\nglove_word_to_id = glove_weights[1]\nglove_vectors = glove_weights[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:43.671549Z","iopub.execute_input":"2024-04-13T08:39:43.671867Z","iopub.status.idle":"2024-04-13T08:39:43.698652Z","shell.execute_reply.started":"2024-04-13T08:39:43.671840Z","shell.execute_reply":"2024-04-13T08:39:43.697873Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"complete = ' '.join(df['review_2'].tolist()).split()\nprint(len(complete))\n\n# word_list = []\n\n# stop_words = set(stopwords.words('english')) \n# for sent in x_train:\n#     for word in sent.lower().split():\n#         word = preprocess_string(word)\n#         if word not in stop_words and word != '':\n#             word_list.append(word)\n            \ncounter = Counter(complete)\n\nprint(counter.most_common(10))\n\ncorpus = sorted(counter, key=counter.get, reverse=True)[:2000]\nword_to_id = {word:i+1 for i, word in enumerate(corpus)}\nid_to_word = {i+1:word for i, word in enumerate(corpus)}\n\ntrain_sequences, test_sequences = list(), list()\n\nfor train_sent in x_train:\n    #set_trace()\n    train_sequence = [word_to_id[word] for word in train_sent.split() if word in word_to_id.keys()]\n    train_sequences.append(train_sequence)\n    \nfor test_sent in x_test:\n    test_sequence = [word_to_id[word] for word in test_sent.split() if word in word_to_id.keys()]\n    test_sequences.append(test_sequence)\n    \nlist(map(len, [train_sequences, test_sequences]))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:46.589041Z","iopub.execute_input":"2024-04-13T08:39:46.589804Z","iopub.status.idle":"2024-04-13T08:39:50.613181Z","shell.execute_reply.started":"2024-04-13T08:39:46.589772Z","shell.execute_reply":"2024-04-13T08:39:50.612254Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"6232887\n[('movie', 87935), ('film', 79675), ('one', 53585), ('like', 40160), ('it', 29982), ('good', 29737), ('the', 28864), ('time', 25099), ('even', 24856), ('would', 24599)]\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"[45000, 5000]"},"metadata":{}}]},{"cell_type":"code","source":"size_vocab = 2000\nglove_dim = glove_embed_dim\nweight_matrix = np.zeros((size_vocab+1, glove_dim))\n\nfor word, id_ in word_to_id.items():\n    glove_id = glove_word_to_id[word]\n    weight_matrix[id_] = glove_vectors[glove_id]\n                                       \nweight_matrix = weight_matrix.astype(np.float32)\nprint(weight_matrix.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:51.918073Z","iopub.execute_input":"2024-04-13T08:39:51.918991Z","iopub.status.idle":"2024-04-13T08:39:51.951610Z","shell.execute_reply.started":"2024-04-13T08:39:51.918961Z","shell.execute_reply":"2024-04-13T08:39:51.950655Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"float32\n","output_type":"stream"}]},{"cell_type":"code","source":"def padding_(sentences, seq_len):\n    features = np.zeros((len(sentences), seq_len),dtype=int)\n    for ii, review in enumerate(sentences):\n        if len(review) != 0:\n            #features[ii, -len(review):] = np.array(review)[:seq_len]\n            features[ii, :len(review)] = np.array(review)[:seq_len]\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:55.448125Z","iopub.execute_input":"2024-04-13T08:39:55.448831Z","iopub.status.idle":"2024-04-13T08:39:55.454351Z","shell.execute_reply.started":"2024-04-13T08:39:55.448800Z","shell.execute_reply":"2024-04-13T08:39:55.453343Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#we have very less number of reviews with length > 500.\n#So we will consideronly those below it.\nx_train_pad = torch.tensor(padding_(train_sequences,200))\nx_test_pad = torch.tensor(padding_(test_sequences,200))\nx_train_pad.shape, x_test_pad.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:55.998691Z","iopub.execute_input":"2024-04-13T08:39:55.999078Z","iopub.status.idle":"2024-04-13T08:39:56.566592Z","shell.execute_reply.started":"2024-04-13T08:39:55.999035Z","shell.execute_reply":"2024-04-13T08:39:56.565791Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(torch.Size([45000, 200]), torch.Size([5000, 200]))"},"metadata":{}}]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, n_vocab, embed_dim, input_dim, hidden_size, fc1_dim, output_dim, bidirectional=False, use_glove=False):\n        super().__init__()\n        self.bidirectional = bidirectional\n        if use_glove:\n            self.embedding = nn.Embedding.from_pretrained(torch.tensor(weight_matrix), freeze=True)\n        else:\n            self.embedding = nn.Embedding(n_vocab, embed_dim)\n        #self.embedding = nn.Embedding.from_pretrained(torch.tensor(weight_matrix), freeze=False)\n        self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True, bidirectional=bidirectional)\n        if bidirectional:\n            self.fc1 = nn.Linear(hidden_size*2, fc1_dim)\n        else:\n            self.fc1 = nn.Linear(hidden_size, fc1_dim)\n        self.output = nn.Linear(fc1_dim, output_dim)\n        self.dropout = nn.Dropout(0.7)\n        \n    def forward(self, x):\n        #set_trace()\n        x = self.embedding(x)\n        x = self.dropout(x)\n        output, (h0, c0) = self.lstm(x)\n        if self.bidirectional:\n            #h0 = h0.view(h0.size(1), -1)\n            h0 = torch.cat((h0[-2, :, :], h0[-1, :, :]), dim=1)\n        x = F.relu(self.fc1(h0))\n        x = F.sigmoid(self.output(x))\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:56.568079Z","iopub.execute_input":"2024-04-13T08:39:56.568372Z","iopub.status.idle":"2024-04-13T08:39:56.578271Z","shell.execute_reply.started":"2024-04-13T08:39:56.568347Z","shell.execute_reply":"2024-04-13T08:39:56.577328Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"n_vocab = len(word_to_id) + 1\nembed_dim = 50 # use for using random embedding layer\ninput_dim = glove_embed_dim # use the dimension of glove embedding when you use glove\nhidden_size = 32\nfc1_dim = 50\noutput_dim = 1\nbatch_size = 128\nbatch_per_epoch = x_train_pad.shape[0] // batch_size\n\ntrain_padded, train_y = x_train_pad.to(device).long(), torch.tensor(y_train, dtype=torch.float).to(device)\nval_padded, val_y = x_test_pad.to(device).long(), torch.tensor(y_test, dtype=torch.float).to(device)\n\nlstm_classifier = LSTMClassifier(n_vocab, embed_dim, input_dim, hidden_size, fc1_dim, output_dim, False, True).to(device)\nloss_function = nn.BCELoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(lstm_classifier.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:41:30.726295Z","iopub.execute_input":"2024-04-13T08:41:30.727396Z","iopub.status.idle":"2024-04-13T08:41:30.763782Z","shell.execute_reply.started":"2024-04-13T08:41:30.727358Z","shell.execute_reply":"2024-04-13T08:41:30.762960Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, y_batch):\n    optimizer.zero_grad()\n    output = lstm_classifier(x_batch)\n    #set_trace()\n    \n    loss = loss_function(output.view(-1), y_batch.view(-1))\n    \n    correct = 0\n    correct += ((output.view(-1) > 0.5).float() == y_batch).float().sum()\n    accuracy = correct / y_batch.shape[0]\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:41:31.016585Z","iopub.execute_input":"2024-04-13T08:41:31.017202Z","iopub.status.idle":"2024-04-13T08:41:31.023451Z","shell.execute_reply.started":"2024-04-13T08:41:31.017173Z","shell.execute_reply":"2024-04-13T08:41:31.022461Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(outputs, labels):\n    correct = 0\n    #correct += (torch.argmax(F.softmax(outputs, dim=-1), dim=-1) == labels).float().sum()\n    correct += ((outputs.view(-1) > 0.5).float() == labels).float().sum()\n    return correct / labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:41:31.528554Z","iopub.execute_input":"2024-04-13T08:41:31.529238Z","iopub.status.idle":"2024-04-13T08:41:31.534186Z","shell.execute_reply.started":"2024-04-13T08:41:31.529206Z","shell.execute_reply":"2024-04-13T08:41:31.533217Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0, 20):\n    train_loss, val_loss = 0, 0\n    training_accuracy = 0\n    lstm_classifier.train(True)\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch = train_padded[start:start+batch_size], train_y[start:start+batch_size]\n#         x_batch, y_batch, mask = x_batch.to(device).long(), y_batch.to(device).long(), mask.to(device).long()\n\n        loss, accuracy = train_epoch(x_batch, y_batch)\n        train_loss += loss\n        training_accuracy += accuracy\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')\n    print(f'Accuracy at Epoch {epoch} is {training_accuracy / (batch_per_epoch)}')\n    \n    lstm_classifier.eval()\n    with torch.no_grad():\n        output_val = lstm_classifier(val_padded)\n        \n        loss_val = loss_function(output_val.view(-1), val_y.view(-1))\n        \n        accuracy = calculate_accuracy(output_val, val_y)\n        \n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        print(f'Accuracy at Epoch {epoch} is {accuracy}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:41:31.842482Z","iopub.execute_input":"2024-04-13T08:41:31.843302Z","iopub.status.idle":"2024-04-13T08:41:53.490268Z","shell.execute_reply.started":"2024-04-13T08:41:31.843270Z","shell.execute_reply":"2024-04-13T08:41:53.489386Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Epoch 0 Loss: 0.6932788491249084\nAccuracy at Epoch 0 is 0.501224160194397\nEpoch 0 Val loss: 0.6928372979164124\nAccuracy at Epoch 0 is 0.5067999958992004\n\nEpoch 1 Loss: 0.69303959608078\nAccuracy at Epoch 1 is 0.5008235573768616\nEpoch 1 Val loss: 0.6929829120635986\nAccuracy at Epoch 1 is 0.5009999871253967\n\nEpoch 2 Loss: 0.6919971704483032\nAccuracy at Epoch 2 is 0.50356125831604\nEpoch 2 Val loss: 0.6927545666694641\nAccuracy at Epoch 2 is 0.5037999749183655\n\nEpoch 3 Loss: 0.6800069212913513\nAccuracy at Epoch 3 is 0.5559784770011902\nEpoch 3 Val loss: 0.6611133813858032\nAccuracy at Epoch 3 is 0.6029999852180481\n\nEpoch 4 Loss: 0.672572135925293\nAccuracy at Epoch 4 is 0.5874732732772827\nEpoch 4 Val loss: 0.6717137098312378\nAccuracy at Epoch 4 is 0.564799964427948\n\nEpoch 5 Loss: 0.6827079057693481\nAccuracy at Epoch 5 is 0.5370370149612427\nEpoch 5 Val loss: 0.6665339469909668\nAccuracy at Epoch 5 is 0.573199987411499\n\nEpoch 6 Loss: 0.6830095052719116\nAccuracy at Epoch 6 is 0.5541755557060242\nEpoch 6 Val loss: 0.6925110220909119\nAccuracy at Epoch 6 is 0.5081999897956848\n\nEpoch 7 Loss: 0.6921409368515015\nAccuracy at Epoch 7 is 0.5022702813148499\nEpoch 7 Val loss: 0.6916916966438293\nAccuracy at Epoch 7 is 0.5041999816894531\n\nEpoch 8 Loss: 0.6913226246833801\nAccuracy at Epoch 8 is 0.5023148059844971\nEpoch 8 Val loss: 0.6891461610794067\nAccuracy at Epoch 8 is 0.5095999836921692\n\nEpoch 9 Loss: 0.680603563785553\nAccuracy at Epoch 9 is 0.5467414259910583\nEpoch 9 Val loss: 0.6433329582214355\nAccuracy at Epoch 9 is 0.6549999713897705\n\nEpoch 10 Loss: 0.6613627672195435\nAccuracy at Epoch 10 is 0.61807781457901\nEpoch 10 Val loss: 0.6453043818473816\nAccuracy at Epoch 10 is 0.6539999842643738\n\nEpoch 11 Loss: 0.6592103838920593\nAccuracy at Epoch 11 is 0.6248664259910583\nEpoch 11 Val loss: 0.6425984501838684\nAccuracy at Epoch 11 is 0.6570000052452087\n\nEpoch 12 Loss: 0.6572273969650269\nAccuracy at Epoch 12 is 0.6303864121437073\nEpoch 12 Val loss: 0.6429775953292847\nAccuracy at Epoch 12 is 0.6575999855995178\n\nEpoch 13 Loss: 0.6573713421821594\nAccuracy at Epoch 13 is 0.6298744678497314\nEpoch 13 Val loss: 0.6417917609214783\nAccuracy at Epoch 13 is 0.6588000059127808\n\nEpoch 14 Loss: 0.6554962396621704\nAccuracy at Epoch 14 is 0.6346598863601685\nEpoch 14 Val loss: 0.6500797867774963\nAccuracy at Epoch 14 is 0.6425999999046326\n\nEpoch 15 Loss: 0.6524244546890259\nAccuracy at Epoch 15 is 0.6343260407447815\nEpoch 15 Val loss: 0.6546623110771179\nAccuracy at Epoch 15 is 0.6186000108718872\n\nEpoch 16 Loss: 0.6552830934524536\nAccuracy at Epoch 16 is 0.6227964758872986\nEpoch 16 Val loss: 0.653061032295227\nAccuracy at Epoch 16 is 0.6227999925613403\n\nEpoch 17 Loss: 0.6621677279472351\nAccuracy at Epoch 17 is 0.5964877009391785\nEpoch 17 Val loss: 0.663771390914917\nAccuracy at Epoch 17 is 0.5867999792098999\n\nEpoch 18 Loss: 0.6749701499938965\nAccuracy at Epoch 18 is 0.5497462749481201\nEpoch 18 Val loss: 0.6619216799736023\nAccuracy at Epoch 18 is 0.5848000049591064\n\nEpoch 19 Loss: 0.6582580804824829\nAccuracy at Epoch 19 is 0.608128547668457\nEpoch 19 Val loss: 0.6481671929359436\nAccuracy at Epoch 19 is 0.6416000127792358\n\n","output_type":"stream"}]}]}