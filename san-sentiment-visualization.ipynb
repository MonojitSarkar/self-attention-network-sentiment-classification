{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":29869,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport torch.optim as optim\nfrom IPython.core.debugger import set_trace\nfrom collections import Counter\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.data.utils import get_tokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T14:31:15.291948Z","iopub.execute_input":"2024-04-07T14:31:15.292527Z","iopub.status.idle":"2024-04-07T14:31:18.555042Z","shell.execute_reply.started":"2024-04-07T14:31:15.292476Z","shell.execute_reply":"2024-04-07T14:31:18.554234Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\n\n# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")\n      \nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:18.556983Z","iopub.execute_input":"2024-04-07T14:31:18.557275Z","iopub.status.idle":"2024-04-07T14:31:18.628372Z","shell.execute_reply.started":"2024-04-07T14:31:18.557227Z","shell.execute_reply":"2024-04-07T14:31:18.627585Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"GPU is available\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"base_csv = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'\ndf = pd.read_csv(base_csv)\ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-04-07T14:31:18.630018Z","iopub.execute_input":"2024-04-07T14:31:18.630325Z","iopub.status.idle":"2024-04-07T14:31:19.718100Z","shell.execute_reply.started":"2024-04-07T14:31:18.630286Z","shell.execute_reply":"2024-04-07T14:31:19.717232Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Analysing sentiment","metadata":{}},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"stop_words = list(set(stopwords.words('english')))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:19.719453Z","iopub.execute_input":"2024-04-07T14:31:19.719730Z","iopub.status.idle":"2024-04-07T14:31:19.727755Z","shell.execute_reply.started":"2024-04-07T14:31:19.719702Z","shell.execute_reply":"2024-04-07T14:31:19.727193Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def preprocess_string(s):\n    s = s.lower()\n    s = ' '.join([word for word in s.split() if word not in stop_words])\n    # replace <br /><br /> with nothing\n    s = re.sub('<[^>]+>', '', s)\n    # Remove all non-word characters (everything except numbers and letters)\n    s = re.sub(r\"[^\\w\\s]\", ' ', s)\n    # Replace all runs of whitespaces with no space\n    s = re.sub(r\"\\s+\", ' ', s)\n    # replace digits with no space\n    s = re.sub(r\"\\d\", '', s)\n    \n    # remove single characters\n    s = ' '.join(list(filter(lambda x: len(x)!=1, s.split())))\n    \n\n    return s","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:19.731476Z","iopub.execute_input":"2024-04-07T14:31:19.731755Z","iopub.status.idle":"2024-04-07T14:31:19.738958Z","shell.execute_reply.started":"2024-04-07T14:31:19.731724Z","shell.execute_reply":"2024-04-07T14:31:19.738333Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.loc[:, 'review'] = df.loc[:, 'review'].apply(preprocess_string)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:19.741912Z","iopub.execute_input":"2024-04-07T14:31:19.742142Z","iopub.status.idle":"2024-04-07T14:31:53.101557Z","shell.execute_reply.started":"2024-04-07T14:31:19.742117Z","shell.execute_reply":"2024-04-07T14:31:53.100638Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"complete = ' '.join(df['review'].tolist()).split()\ncounter = Counter(complete)\n# words like could, would could be removed.\nmost_occur = counter.most_common(4)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:53.103542Z","iopub.execute_input":"2024-04-07T14:31:53.103792Z","iopub.status.idle":"2024-04-07T14:31:54.848842Z","shell.execute_reply.started":"2024-04-07T14:31:53.103753Z","shell.execute_reply":"2024-04-07T14:31:54.847906Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X,y = df['review'].values,df['sentiment'].values\nx_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\nprint(f'shape of train data is {x_train.shape}')\nprint(f'shape of test data is {x_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:54.850444Z","iopub.execute_input":"2024-04-07T14:31:54.850811Z","iopub.status.idle":"2024-04-07T14:31:54.941201Z","shell.execute_reply.started":"2024-04-07T14:31:54.850727Z","shell.execute_reply":"2024-04-07T14:31:54.940521Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"shape of train data is (37500,)\nshape of test data is (12500,)\n","output_type":"stream"}]},{"cell_type":"code","source":"np.__version__","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:54.942425Z","iopub.execute_input":"2024-04-07T14:31:54.942639Z","iopub.status.idle":"2024-04-07T14:31:54.947150Z","shell.execute_reply.started":"2024-04-07T14:31:54.942614Z","shell.execute_reply":"2024-04-07T14:31:54.946356Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'1.18.2'"},"metadata":{}}]},{"cell_type":"code","source":"def tockenize(x_train,y_train,x_val,y_val):\n    word_list = []\n\n    stop_words = set(stopwords.words('english')) \n    for sent in x_train:\n        for word in sent.lower().split():\n            word = preprocess_string(word)\n            if word not in stop_words and word != '':\n                word_list.append(word)\n  \n    corpus = Counter(word_list)\n    # sorting on the basis of most common words\n    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:2000]\n    # creating a dict\n    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n    \n    # tockenize\n    final_list_train,final_list_test = [],[]\n    for sent in x_train:\n            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                     if preprocess_string(word) in onehot_dict.keys()])\n    for sent in x_val:\n            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                    if preprocess_string(word) in onehot_dict.keys()])\n            \n    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:54.948379Z","iopub.execute_input":"2024-04-07T14:31:54.948587Z","iopub.status.idle":"2024-04-07T14:31:55.033949Z","shell.execute_reply.started":"2024-04-07T14:31:54.948563Z","shell.execute_reply":"2024-04-07T14:31:55.033041Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:31:55.035446Z","iopub.execute_input":"2024-04-07T14:31:55.035907Z","iopub.status.idle":"2024-04-07T14:35:04.807536Z","shell.execute_reply.started":"2024-04-07T14:31:55.035866Z","shell.execute_reply":"2024-04-07T14:35:04.806893Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(f'Length of vocabulary is {len(vocab)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:04.808990Z","iopub.execute_input":"2024-04-07T14:35:04.809287Z","iopub.status.idle":"2024-04-07T14:35:04.813967Z","shell.execute_reply.started":"2024-04-07T14:35:04.809253Z","shell.execute_reply":"2024-04-07T14:35:04.813114Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Length of vocabulary is 2000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Analysing review length","metadata":{}},{"cell_type":"code","source":"rev_len = [len(i) for i in x_train]\npd.Series(rev_len).hist()\nplt.show()\npd.Series(rev_len).describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:04.815294Z","iopub.execute_input":"2024-04-07T14:35:04.815571Z","iopub.status.idle":"2024-04-07T14:35:05.058260Z","shell.execute_reply.started":"2024-04-07T14:35:04.815536Z","shell.execute_reply":"2024-04-07T14:35:05.057394Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAY7UlEQVR4nO3dfZBV9Z3n8fdnIRpHxoBRuxhgtrGmk43KhEiXknIndYlRW5MKZivZhaKEJEx1ksKqpJaqDc6T2ThWMbsh7lqbYaYzMmJNxo4TY6QUh+lhvOtS5QOQEAGJodWe2IGFjeDDRcuZZr/7x/l19qS9/XAf6HvP8HlV3brnfM/5nfu93S0fz8O9RxGBmZmd3f5VqxswM7PWcxiYmZnDwMzMHAZmZobDwMzMgJmtbqBeF110UXR2dtY87tSpU5x//vnNb2gaFLX3ovYN7r1Vitp7Efreu3fvLyLi4rH1woZBZ2cne/bsqXlcuVymVCo1v6FpUNTei9o3uPdWKWrvRehb0j9Wq/swkZmZOQzMzMxhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQX+BHIjOjc82pLXHdr48Za8rpnZZLxnYGZmDgMzM3MYmJkZDgMzM2MKYSBpgaTHJR2SdFDSl1P9QkkDkg6n5zmpLkl3SxqU9KykK3PbWpPWPyxpTa6+RNL+NOZuSToTb9bMzKqbyp7BCLA+Ij4ALAXWSboM2ADsjIguYGeaB7gR6EqPXmAzZOEB3A5cDVwF3D4aIGmd3ty4nsbfmpmZTdWkYRARRyPih2n6DeAQMA9YDmxNq20Fbk7Ty4H7IvMUMFvSXOAGYCAiTkTESWAA6EnLLoiIJyMigPty2zIzs2lQ0+cMJHUCHwKeBjoi4ihkgSHpkrTaPODl3LDhVJuoPlylXu31e8n2IOjo6KBcLtfSPgCVSoX1i07XPK4Z6uk3r1KpNLyNVihq3+DeW6WovRe1b6ghDCTNAh4EvhIRr09wWL/agqij/s5iRB/QB9Dd3R313F6uXC6zadepmsc1w9CqUkPji3BLvWqK2je491Ypau9F7RumeDWRpHeRBcF3IuL7qXwsHeIhPR9P9WFgQW74fODIJPX5VepmZjZNpnI1kYB7gEMR8c3com3A6BVBa4CHc/XV6aqipcBr6XDSDuB6SXPSiePrgR1p2RuSlqbXWp3blpmZTYOpHCa6BrgF2C9pX6r9HrAReEDSWuBnwGfSsu3ATcAg8CbwOYCIOCHpDmB3Wu/rEXEiTX8JuBc4D3gsPczMbJpMGgYRsYvqx/UBrq2yfgDrxtnWFmBLlfoe4IrJejEzszPDn0A2MzOHgZmZOQzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRlTu+3lFknHJR3I1b4raV96DI3eAU1Sp6S3csv+LDdmiaT9kgYl3Z1ucYmkCyUNSDqcnueciTdqZmbjm8qewb1AT74QEf8hIhZHxGLgQeD7ucUvjC6LiC/m6puBXqArPUa3uQHYGRFdwM40b2Zm02jSMIiIJ4AT1Zal/7v/98D9E21D0lzggoh4Mt0W8z7g5rR4ObA1TW/N1c3MbJoo+7d5kpWkTuCRiLhiTP0jwDcjoju33kHgp8DrwB9ExP+S1A1sjIiPpfV+B/hqRHxC0qsRMTu3zZMRUfVQkaResr0LOjo6lvT399f2boFKpcJLr52ueVwzLJr3nobGVyoVZs2a1aRupk9R+wb33ipF7b0IfS9btmzv6L/ZeTMb3O5KfnWv4CjwmxHxiqQlwA8kXQ6oytjJU2jsgIg+oA+gu7s7SqVSzQ2Xy2U27TpV87hmGFpVamh8uVymnvfcakXtG9x7qxS196L2DQ2EgaSZwL8DlozWIuJt4O00vVfSC8D7gGFgfm74fOBImj4maW5EHE2Hk47X25OZmdWnkUtLPwb8JCKGRwuSLpY0I01fSnai+MWIOAq8IWlpOs+wGng4DdsGrEnTa3J1MzObJlO5tPR+4Eng/ZKGJa1Ni1bwzhPHHwGelfRj4HvAFyNi9OTzl4C/AAaBF4DHUn0jcJ2kw8B1ad7MzKbRpIeJImLlOPXPVqk9SHapabX19wBXVKm/Alw7WR9mZnbm+BPIZmbmMDAzM4eBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGVO7uc0WScclHcjVvibp55L2pcdNuWW3SRqU9LykG3L1nlQblLQhV18o6WlJhyV9V9I5zXyDZmY2uansGdwL9FSp3xURi9NjO4Cky8jugHZ5GvOnkmakW2F+C7gRuAxYmdYF+JO0rS7gJLB27AuZmdmZNWkYRMQTwInJ1kuWA/0R8XZEvER2i8ur0mMwIl6MiH8C+oHl6X7IHyW7RSbAVuDmGt+DmZk1qJFzBrdKejYdRpqTavOAl3PrDKfaePX3Aq9GxMiYupmZTaNJ74E8js3AHUCk503A5wFVWTeoHjoxwfpVSeoFegE6Ojool8s1NQ1QqVRYv+h0zeOaoZ5+8yqVSsPbaIWi9g3uvVWK2ntR+4Y6wyAijo1OS/o28EiaHQYW5FadDxxJ09XqvwBmS5qZ9g7y61d73T6gD6C7uztKpVLNvZfLZTbtOlXzuGYYWlVqaHy5XKae99xqRe0b3HurFLX3ovYNdR4mkjQ3N/spYPRKo23ACknnSloIdAHPALuBrnTl0DlkJ5m3RUQAjwOfTuPXAA/X05OZmdVv0j0DSfcDJeAiScPA7UBJ0mKyQzpDwBcAIuKgpAeA54ARYF1EnE7buRXYAcwAtkTEwfQSXwX6Jf0x8CPgnqa9OzMzm5JJwyAiVlYpj/sPdkTcCdxZpb4d2F6l/iLZ1UZmZtYi/gSymZk5DMzMzGFgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMyYQhhI2iLpuKQDudp/lfQTSc9KekjS7FTvlPSWpH3p8We5MUsk7Zc0KOluSUr1CyUNSDqcnueciTdqZmbjm8qewb1Az5jaAHBFRPw28FPgttyyFyJicXp8MVffDPSS3Re5K7fNDcDOiOgCdqZ5MzObRpOGQUQ8AZwYU/u7iBhJs08B8yfahqS5wAUR8WREBHAfcHNavBzYmqa35upmZjZNmnHO4PPAY7n5hZJ+JOl/SvqdVJsHDOfWGU41gI6IOAqQni9pQk9mZlaDmY0MlvT7wAjwnVQ6CvxmRLwiaQnwA0mXA6oyPOp4vV6yQ010dHRQLpdr7rlSqbB+0emaxzVDPf3mVSqVhrfRCkXtG9x7qxS196L2DQ2EgaQ1wCeAa9OhHyLibeDtNL1X0gvA+8j2BPKHkuYDR9L0MUlzI+JoOpx0fLzXjIg+oA+gu7s7SqVSzX2Xy2U27TpV87hmGFpVamh8uVymnvfcakXtG9x7qxS196L2DXUeJpLUA3wV+GREvJmrXyxpRpq+lOxE8Yvp8M8bkpamq4hWAw+nYduANWl6Ta5uZmbTZNI9A0n3AyXgIknDwO1kVw+dCwykK0SfSlcOfQT4uqQR4DTwxYgYPfn8JbIrk84jO8cwep5hI/CApLXAz4DPNOWdmZnZlE0aBhGxskr5nnHWfRB4cJxle4ArqtRfAa6drA8zMztz/AlkMzNzGJiZmcPAzMxwGJiZGQ4DMzOjwU8gW206Nzza0Pj1i0b4bJ3bGNr48YZe28z+ZfOegZmZOQzMzMxhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzNjimEgaYuk45IO5GoXShqQdDg9z0l1Sbpb0qCkZyVdmRuzJq1/ON1DebS+RNL+NObudGtMMzObJlPdM7gX6BlT2wDsjIguYGeaB7iR7N7HXUAvsBmy8CC7ZebVwFXA7aMBktbpzY0b+1pmZnYGTSkMIuIJ4MSY8nJga5reCtycq98XmaeA2ZLmAjcAAxFxIiJOAgNAT1p2QUQ8GREB3JfblpmZTYNGvrW0IyKOAkTEUUmXpPo84OXcesOpNlF9uEr9HST1ku1B0NHRQblcrrnpSqXC+kWnax7XDjrOy765tB71/KyapVKptPT1G+HeW6OovRe1bzgzX2Fd7Xh/1FF/ZzGiD+gD6O7ujlKpVHNz5XKZTbtO1TyuHaxfNMKm/fX9yoZWlZrbTA3K5TL1/K7agXtvjaL2XtS+obGriY6lQzyk5+OpPgwsyK03HzgySX1+lbqZmU2TRsJgGzB6RdAa4OFcfXW6qmgp8Fo6nLQDuF7SnHTi+HpgR1r2hqSl6Sqi1bltmZnZNJjSMQdJ9wMl4CJJw2RXBW0EHpC0FvgZ8Jm0+nbgJmAQeBP4HEBEnJB0B7A7rff1iBg9Kf0lsiuWzgMeSw8zM5smUwqDiFg5zqJrq6wbwLpxtrMF2FKlvge4Yiq9mJlZ8/kTyGZm5jAwMzOHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzo4EwkPR+Sftyj9clfUXS1yT9PFe/KTfmNkmDkp6XdEOu3pNqg5I2NPqmzMysNlO601k1EfE8sBhA0gzg58BDZLe5vCsivpFfX9JlwArgcuA3gL+X9L60+FvAdcAwsFvStoh4rt7ezMysNnWHwRjXAi9ExD9m97SvajnQHxFvAy9JGgSuSssGI+JFAEn9aV2HgZnZNGlWGKwA7s/N3yppNbAHWB8RJ4F5wFO5dYZTDeDlMfWrq72IpF6gF6Cjo4NyuVxzo5VKhfWLTtc8rh10nAfrF43UNbaen1WzVCqVlr5+I9x7axS196L2DU0IA0nnAJ8EbkulzcAdQKTnTcDngWq7DEH18xZR7bUiog/oA+ju7o5SqVRzv+VymU27TtU8rh2sXzTCpv31/cqGVpWa20wNyuUy9fyu2oF7b42i9l7UvqE5ewY3Aj+MiGMAo88Akr4NPJJmh4EFuXHzgSNpery6mZlNg2ZcWrqS3CEiSXNzyz4FHEjT24AVks6VtBDoAp4BdgNdkhamvYwVaV0zM5smDe0ZSPo1squAvpAr/xdJi8kO9QyNLouIg5IeIDsxPAKsi4jTaTu3AjuAGcCWiDjYSF9mZlabhsIgIt4E3jumdssE698J3Fmlvh3Y3kgvZmZWP38C2czMHAZmZuYwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmNCEMJA1J2i9pn6Q9qXahpAFJh9PznFSXpLslDUp6VtKVue2sSesflrSm0b7MzGzqmrVnsCwiFkdEd5rfAOyMiC5gZ5oHuJHs3sddQC+wGbLwAG4HrgauAm4fDRAzMzvzztRhouXA1jS9Fbg5V78vMk8BsyXNBW4ABiLiREScBAaAnjPUm5mZjaGIaGwD0kvASSCAP4+IPkmvRsTs3DonI2KOpEeAjRGxK9V3Al8FSsC7I+KPU/0Pgbci4htjXquXbI+Cjo6OJf39/TX3W6lUeOm103W809brOA+OvVXf2EXz3tPcZmpQqVSYNWtWy16/Ee69NYraexH6XrZs2d7cUZxfmtmEbV8TEUckXQIMSPrJBOuqSi0mqP9qIaIP6APo7u6OUqlUc7PlcplNu07VPK4drF80wqb99f3KhlaVmttMDcrlMvX8rtqBe2+NovZe1L6hCYeJIuJIej4OPER2zP9YOvxDej6eVh8GFuSGzweOTFA3M7Np0FAYSDpf0q+PTgPXAweAbcDoFUFrgIfT9DZgdbqqaCnwWkQcBXYA10uak04cX59qZmY2DRo9TNQBPCRpdFt/HRF/K2k38ICktcDPgM+k9bcDNwGDwJvA5wAi4oSkO4Ddab2vR8SJBnszM7MpaigMIuJF4INV6q8A11apB7BunG1tAbY00o+ZmdXHn0A2MzOHgZmZOQzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMyM5tzPwAqgc8OjLXndoY0fb8nrmlltvGdgZmYOAzMzcxiYmRkOAzMzo4EwkLRA0uOSDkk6KOnLqf41ST+XtC89bsqNuU3SoKTnJd2Qq/ek2qCkDY29JTMzq1UjVxONAOsj4ofpPsh7JQ2kZXdFxDfyK0u6DFgBXA78BvD3kt6XFn8LuA4YBnZL2hYRzzXQm5mZ1aDuMEg3sj+apt+QdAiYN8GQ5UB/RLwNvCRpELgqLRtMt9BEUn9a12FgZjZNlN2WuMGNSJ3AE8AVwH8EPgu8Duwh23s4Kel/AE9FxF+lMfcAj6VN9ETE76b6LcDVEXFrldfpBXoBOjo6lvT399fca6VS4aXXTtc8rh10nAfH3mp1F7VZNO89VCoVZs2a1epW6uLeW6OovReh72XLlu2NiO6x9YY/dCZpFvAg8JWIeF3SZuAOINLzJuDzgKoMD6qft6iaUBHRB/QBdHd3R6lUqrnfcrnMpl2nah7XDtYvGmHT/mJ9TnBoVYlyuUw9v6t24N5bo6i9F7VvaDAMJL2LLAi+ExHfB4iIY7nl3wYeSbPDwILc8PnAkTQ9Xt3MzKZBI1cTCbgHOBQR38zV5+ZW+xRwIE1vA1ZIOlfSQqALeAbYDXRJWijpHLKTzNvq7cvMzGrXyJ7BNcAtwH5J+1Lt94CVkhaTHeoZAr4AEBEHJT1AdmJ4BFgXEacBJN0K7ABmAFsi4mADfZmZWY0auZpoF9XPA2yfYMydwJ1V6tsnGmdmZmeWP4FsZmYOAzMzcxiYmRkOAzMzw2FgZmY4DMzMDIeBmZnRhO8mMptI54ZHWb9ohM9ueHTaX3to48en/TXNisp7BmZm5jAwMzOHgZmZ4TAwMzMcBmZmhq8msn/BOptwBVM9V0L5KiYrIu8ZmJmZw8DMzNooDCT1SHpe0qCkDa3ux8zsbNIW5wwkzQC+BVwHDAO7JW2LiOda25lZ7ZpxrqJePl9h9WqXPYOrgMGIeDEi/gnoB5a3uCczs7OGIqLVPSDp00BPRPxumr8FuDoibh2zXi/Qm2bfDzxfx8tdBPyigXZbqai9F7VvcO+tUtTei9D3v46Ii8cW2+IwEaAqtXekVET0AX0NvZC0JyK6G9lGqxS196L2De69VYrae1H7hvY5TDQMLMjNzweOtKgXM7OzTruEwW6gS9JCSecAK4BtLe7JzOys0RaHiSJiRNKtwA5gBrAlIg6eoZdr6DBTixW196L2De69VYrae1H7bo8TyGZm1lrtcpjIzMxayGFgZmZnVxi081deSNoi6bikA7nahZIGJB1Oz3NSXZLuTu/jWUlXtq5zkLRA0uOSDkk6KOnLRelf0rslPSPpx6n3/5zqCyU9nXr/brqwAUnnpvnBtLyzVb2nfmZI+pGkRwrW95Ck/ZL2SdqTam3/95L6mS3pe5J+kv7mP1yU3idy1oRB7isvbgQuA1ZKuqy1Xf2Ke4GeMbUNwM6I6AJ2pnnI3kNXevQCm6epx/GMAOsj4gPAUmBd+tkWof+3gY9GxAeBxUCPpKXAnwB3pd5PAmvT+muBkxHxW8Bdab1W+jJwKDdflL4BlkXE4tx1+UX4ewH478DfRsS/AT5I9vMvSu/ji4iz4gF8GNiRm78NuK3VfY3psRM4kJt/HpibpucCz6fpPwdWVluvHR7Aw2TfM1Wo/oFfA34IXE32KdKZY/92yK54+3CanpnWU4v6nU/2D89HgUfIPrzZ9n2nHoaAi8bU2v7vBbgAeGnsz64IvU/2OGv2DIB5wMu5+eFUa2cdEXEUID1fkupt+17S4YcPAU9TkP7ToZZ9wHFgAHgBeDUiRqr098ve0/LXgPdOb8e/9N+A/wT83zT/XorRN2TfMPB3kvamr5mBYvy9XAr8H+Av0+G5v5B0PsXofUJnUxhM6SsvCqIt34ukWcCDwFci4vWJVq1Sa1n/EXE6IhaT/Z/2VcAHqq2Wntuid0mfAI5HxN58ucqqbdV3zjURcSXZYZR1kj4ywbrt1PtM4Epgc0R8CDjF/z8kVE079T6hsykMiviVF8ckzQVIz8dTve3ei6R3kQXBdyLi+6lcmP4BIuJVoEx23mO2pNEPZeb7+2Xvafl7gBPT2ykA1wCflDRE9i2/HyXbU2j3vgGIiCPp+TjwEFkIF+HvZRgYjoin0/z3yMKhCL1P6GwKgyJ+5cU2YE2aXkN2LH60vjpdqbAUeG10F7UVJAm4BzgUEd/MLWr7/iVdLGl2mj4P+BjZCcHHgU+n1cb2PvqePg38Q6SDwdMpIm6LiPkR0Un2t/wPEbGKNu8bQNL5kn59dBq4HjhAAf5eIuJ/Ay9Len8qXQs8RwF6n1SrT1pM5wO4Cfgp2THh3291P2N6ux84Cvwz2f9NrCU7prsTOJyeL0zriuzKqBeA/UB3i3v/t2S7vs8C+9LjpiL0D/w28KPU+wHgj1L9UuAZYBD4G+DcVH93mh9Myy9tg7+dEvBIUfpOPf44PQ6O/rdYhL+X1M9iYE/6m/kBMKcovU/08NdRmJnZWXWYyMzMxuEwMDMzh4GZmTkMzMwMh4GZmeEwMDMzHAZmZgb8P/wbaMdJl9ChAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"count    37500.000000\nmean        80.666533\nstd         56.581712\nmin          2.000000\n25%         46.000000\n50%         62.000000\n75%         98.000000\nmax        654.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"def padding_(sentences, seq_len):\n    features = np.zeros((len(sentences), seq_len),dtype=int)\n    for ii, review in enumerate(sentences):\n        if len(review) != 0:\n            #features[ii, -len(review):] = np.array(review)[:seq_len]\n            features[ii, :len(review)] = np.array(review)[:seq_len]\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:05.059627Z","iopub.execute_input":"2024-04-07T14:35:05.060053Z","iopub.status.idle":"2024-04-07T14:35:05.066105Z","shell.execute_reply.started":"2024-04-07T14:35:05.060012Z","shell.execute_reply":"2024-04-07T14:35:05.065388Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#we have very less number of reviews with length > 500.\n#So we will consideronly those below it.\nx_train_pad = torch.tensor(padding_(x_train,200))\nx_test_pad = torch.tensor(padding_(x_test,200))\nx_train_pad.shape, x_test_pad.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:05.067629Z","iopub.execute_input":"2024-04-07T14:35:05.067927Z","iopub.status.idle":"2024-04-07T14:35:06.106973Z","shell.execute_reply.started":"2024-04-07T14:35:05.067891Z","shell.execute_reply":"2024-04-07T14:35:06.106223Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(torch.Size([37500, 200]), torch.Size([12500, 200]))"},"metadata":{}}]},{"cell_type":"code","source":"np.array([[1,2,3], [4,5]])","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.108577Z","iopub.execute_input":"2024-04-07T14:35:06.108940Z","iopub.status.idle":"2024-04-07T14:35:06.115561Z","shell.execute_reply.started":"2024-04-07T14:35:06.108902Z","shell.execute_reply":"2024-04-07T14:35:06.114737Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([list([1, 2, 3]), list([4, 5])], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"x_train_pad[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.117005Z","iopub.execute_input":"2024-04-07T14:35:06.117307Z","iopub.status.idle":"2024-04-07T14:35:06.141230Z","shell.execute_reply.started":"2024-04-07T14:35:06.117271Z","shell.execute_reply":"2024-04-07T14:35:06.140566Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([ 285,    1,   21,   25,  268,   51,   72,  138,   16,   36,   30,  834,\n         464,  198,    1,   22,  667,   30,   69,  234, 1614,   37,   31, 1822,\n        1663,   12,   15,  897,  838,  236,  256,    2,  178, 1007, 1549, 1160,\n         359,   11,  277,    2,  618, 1585,  110,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"def get_masks(padded):\n    B, T = padded.shape\n    mask = torch.eq(padded, 0).to(torch.float32)\n    mask = mask * -1e9\n    masked_reshape = mask.reshape(B, 1, T)\n    return masked_reshape\n\ntrain_mask = get_masks(x_train_pad)\nval_mask = get_masks(x_test_pad)\nprint(train_mask.shape, val_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.142318Z","iopub.execute_input":"2024-04-07T14:35:06.142536Z","iopub.status.idle":"2024-04-07T14:35:06.191799Z","shell.execute_reply.started":"2024-04-07T14:35:06.142512Z","shell.execute_reply":"2024-04-07T14:35:06.190907Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"torch.Size([37500, 1, 200]) torch.Size([12500, 1, 200])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_angle(timesteps, dim):\n    k = np.arange(dim)[np.newaxis, :]\n    i = k // 2\n\n    positions = np.arange(timesteps)[:, np.newaxis]\n    angles = positions / (10000 ** (2*i/dim))\n\n    return angles\n\ndef get_positional_embeddings(angles):\n    angles[:, 0::2] = np.sin(angles[:, 0::2])\n    angles[:, 1::2] = np.cos(angles[:, 1::2])\n\n    return torch.tensor(angles, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.193273Z","iopub.execute_input":"2024-04-07T14:35:06.193599Z","iopub.status.idle":"2024-04-07T14:35:06.202561Z","shell.execute_reply.started":"2024-04-07T14:35:06.193561Z","shell.execute_reply":"2024-04-07T14:35:06.201699Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.204023Z","iopub.execute_input":"2024-04-07T14:35:06.204353Z","iopub.status.idle":"2024-04-07T14:35:06.212887Z","shell.execute_reply.started":"2024-04-07T14:35:06.204317Z","shell.execute_reply":"2024-04-07T14:35:06.212153Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        self.softmax = nn.Softmax(dim=-1)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = self.softmax(wei)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.213912Z","iopub.execute_input":"2024-04-07T14:35:06.214140Z","iopub.status.idle":"2024-04-07T14:35:06.223448Z","shell.execute_reply.started":"2024-04-07T14:35:06.214115Z","shell.execute_reply":"2024-04-07T14:35:06.222750Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.sa = Head(head_size)\n        self.avgpool = nn.AvgPool1d(timesteps)\n        self.inter1_layer = nn.Linear(head_size, head_size)\n        self.output = nn.Linear(head_size, output)\n        \n    def forward(self, x, mask, positional_encoding):\n        B, T = x.shape # validation shape --> (1000, 73)\n#         print(self.embedding(x).shape, positional_encoding.shape)\n        #set_trace()\n        embedding = self.embedding(x) + positional_encoding # (B, timesteps, n_embed)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size)\n        averaged = self.avgpool(sa_out.permute(0, 2, 1)) # (B, head_size, 1)\n        # implement average pooling after sa_out\n        inter1 = self.inter1_layer(averaged.view(B, -1)) # (B, head_size) @ (head_size, head_size) --> (B, headsize)\n        output = self.output(inter1) # (B, head_size) @ (head_size, output) --> (B, output)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.224411Z","iopub.execute_input":"2024-04-07T14:35:06.224639Z","iopub.status.idle":"2024-04-07T14:35:06.237919Z","shell.execute_reply.started":"2024-04-07T14:35:06.224615Z","shell.execute_reply":"2024-04-07T14:35:06.237308Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, mask, y_batch, positional_encoding):\n    optimizer.zero_grad()\n    output = model(x_batch, mask, positional_encoding)\n    #set_trace()\n    output = nn.Sigmoid()(output)\n    \n    \n    loss = loss_function(output.view(-1), y_batch.view(-1))\n    \n    correct = 0\n    correct += ((output.view(-1) > 0.5).float() == y_batch).float().sum()\n    accuracy = correct / y_batch.shape[0]\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.239192Z","iopub.execute_input":"2024-04-07T14:35:06.239410Z","iopub.status.idle":"2024-04-07T14:35:06.248756Z","shell.execute_reply.started":"2024-04-07T14:35:06.239385Z","shell.execute_reply":"2024-04-07T14:35:06.248221Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_positional_encoding.shape, val_positional_encoding.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:47:23.726872Z","iopub.execute_input":"2024-04-07T14:47:23.727184Z","iopub.status.idle":"2024-04-07T14:47:23.733276Z","shell.execute_reply.started":"2024-04-07T14:47:23.727137Z","shell.execute_reply":"2024-04-07T14:47:23.732289Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(torch.Size([200, 32]), torch.Size([200, 32]))"},"metadata":{}}]},{"cell_type":"code","source":"# At 2000 most common words and 200 padding, it outperformed LSTM slightly\nn_embed = 32\ntimesteps = x_train_pad.shape[-1]\nbatch_size = 256\nbatch_per_epoch = x_train_pad.shape[0] // batch_size\n\ntrain_padded, train_y = x_train_pad.to(device).long(), torch.tensor(y_train, dtype=torch.float).to(device)\nval_padded, val_y = x_test_pad.to(device).long(), torch.tensor(y_test, dtype=torch.float).to(device) \ntrain_mask, val_mask = train_mask.to(device), val_mask.to(device)\ntrain_positional_encoding = get_positional_embeddings(get_angle(timesteps, n_embed)).to(device)\nval_positional_encoding = get_positional_embeddings(get_angle(val_padded.shape[-1], n_embed)).to(device)\nprint('Shape of encodings are', train_positional_encoding.shape, val_positional_encoding.shape)\n\n\nmodel = Encoder(len(vocab)+1, n_embed, timesteps, head_size=n_embed, output=1).to(device)\n\nloss_function = nn.BCELoss()\n#loss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n\n#model = nn.DataParallel(model, list(range(torch.cuda.device_count())))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:06.249908Z","iopub.execute_input":"2024-04-07T14:35:06.250117Z","iopub.status.idle":"2024-04-07T14:35:09.707486Z","shell.execute_reply.started":"2024-04-07T14:35:06.250093Z","shell.execute_reply":"2024-04-07T14:35:09.706391Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Shape of encodings are torch.Size([200, 32]) torch.Size([200, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_accuracy(outputs, labels):\n    correct = 0\n    #correct += (torch.argmax(F.softmax(outputs, dim=-1), dim=-1) == labels).float().sum()\n    correct += ((outputs.view(-1) > 0.5).float() == labels).float().sum()\n    return correct / labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:09.709047Z","iopub.execute_input":"2024-04-07T14:35:09.709351Z","iopub.status.idle":"2024-04-07T14:35:09.715010Z","shell.execute_reply.started":"2024-04-07T14:35:09.709315Z","shell.execute_reply":"2024-04-07T14:35:09.714158Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0, 20):\n    train_loss, val_loss = 0, 0\n    training_accuracy = 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = train_padded[start:start+batch_size], train_y[start:start+batch_size], train_mask[start:start+batch_size]\n#         x_batch, y_batch, mask = x_batch.to(device).long(), y_batch.to(device).long(), mask.to(device).long()\n\n        model.train(True)\n    \n        loss, accuracy = train_epoch(x_batch, mask, y_batch, train_positional_encoding)\n        train_loss += loss\n        training_accuracy += accuracy\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')\n    print(f'Accuracy at Epoch {epoch} is {training_accuracy / (batch_per_epoch)}')\n    \n    model.eval()\n    with torch.no_grad():\n        output_val = model(val_padded, val_mask, val_positional_encoding)\n        output_val = nn.Sigmoid()(output_val)\n        \n        loss_val = loss_function(output_val.view(-1), val_y.view(-1))\n        \n        accuracy = calculate_accuracy(output_val, val_y)\n        \n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        print(f'Accuracy at Epoch {epoch} is {accuracy}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:09.716332Z","iopub.execute_input":"2024-04-07T14:35:09.716622Z","iopub.status.idle":"2024-04-07T14:35:32.614634Z","shell.execute_reply.started":"2024-04-07T14:35:09.716584Z","shell.execute_reply":"2024-04-07T14:35:32.613916Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 0 Loss: 0.632503092288971\nAccuracy at Epoch 0 is 0.6274614930152893\nEpoch 0 Val loss: 0.5536753535270691\nAccuracy at Epoch 0 is 0.7179999947547913\n\nEpoch 1 Loss: 0.5229783654212952\nAccuracy at Epoch 1 is 0.7367562055587769\nEpoch 1 Val loss: 0.4897903501987457\nAccuracy at Epoch 1 is 0.7653599977493286\n\nEpoch 2 Loss: 0.45081162452697754\nAccuracy at Epoch 2 is 0.7883668541908264\nEpoch 2 Val loss: 0.43477100133895874\nAccuracy at Epoch 2 is 0.798799991607666\n\nEpoch 3 Loss: 0.397981196641922\nAccuracy at Epoch 3 is 0.8205533027648926\nEpoch 3 Val loss: 0.3953979015350342\nAccuracy at Epoch 3 is 0.8200799822807312\n\nEpoch 4 Loss: 0.3640466034412384\nAccuracy at Epoch 4 is 0.8377301096916199\nEpoch 4 Val loss: 0.3694131374359131\nAccuracy at Epoch 4 is 0.8354399800300598\n\nEpoch 5 Loss: 0.33946338295936584\nAccuracy at Epoch 5 is 0.8517497777938843\nEpoch 5 Val loss: 0.35347098112106323\nAccuracy at Epoch 5 is 0.8447200059890747\n\nEpoch 6 Loss: 0.3224619925022125\nAccuracy at Epoch 6 is 0.8600706458091736\nEpoch 6 Val loss: 0.3421742916107178\nAccuracy at Epoch 6 is 0.8501600027084351\n\nEpoch 7 Loss: 0.30933651328086853\nAccuracy at Epoch 7 is 0.8662242889404297\nEpoch 7 Val loss: 0.33414211869239807\nAccuracy at Epoch 7 is 0.8532800078392029\n\nEpoch 8 Loss: 0.2988412082195282\nAccuracy at Epoch 8 is 0.8718963861465454\nEpoch 8 Val loss: 0.3285406529903412\nAccuracy at Epoch 8 is 0.8574399948120117\n\nEpoch 9 Loss: 0.2902224659919739\nAccuracy at Epoch 9 is 0.8761504888534546\nEpoch 9 Val loss: 0.3245629668235779\nAccuracy at Epoch 9 is 0.8607999682426453\n\nEpoch 10 Loss: 0.28308504819869995\nAccuracy at Epoch 10 is 0.8796018958091736\nEpoch 10 Val loss: 0.32196179032325745\nAccuracy at Epoch 10 is 0.862559974193573\n\nEpoch 11 Loss: 0.2770462930202484\nAccuracy at Epoch 11 is 0.8832941055297852\nEpoch 11 Val loss: 0.320380300283432\nAccuracy at Epoch 11 is 0.8628000020980835\n\nEpoch 12 Loss: 0.2717055082321167\nAccuracy at Epoch 12 is 0.8857555389404297\nEpoch 12 Val loss: 0.31942474842071533\nAccuracy at Epoch 12 is 0.8639999628067017\n\nEpoch 13 Loss: 0.2668452560901642\nAccuracy at Epoch 13 is 0.8881099820137024\nEpoch 13 Val loss: 0.31896620988845825\nAccuracy at Epoch 13 is 0.8642399907112122\n\nEpoch 14 Loss: 0.262412965297699\nAccuracy at Epoch 14 is 0.8906785249710083\nEpoch 14 Val loss: 0.3189736604690552\nAccuracy at Epoch 14 is 0.8642399907112122\n\nEpoch 15 Loss: 0.2583180367946625\nAccuracy at Epoch 15 is 0.8928456902503967\nEpoch 15 Val loss: 0.3193644881248474\nAccuracy at Epoch 15 is 0.8645599484443665\n\nEpoch 16 Loss: 0.2544578015804291\nAccuracy at Epoch 16 is 0.8945580124855042\nEpoch 16 Val loss: 0.320130854845047\nAccuracy at Epoch 16 is 0.865839958190918\n\nEpoch 17 Loss: 0.25077489018440247\nAccuracy at Epoch 17 is 0.8966448903083801\nEpoch 17 Val loss: 0.3212531805038452\nAccuracy at Epoch 17 is 0.8655200004577637\n\nEpoch 18 Loss: 0.24721641838550568\nAccuracy at Epoch 18 is 0.8985980153083801\nEpoch 18 Val loss: 0.3226747512817383\nAccuracy at Epoch 18 is 0.8646399974822998\n\nEpoch 19 Loss: 0.24371902644634247\nAccuracy at Epoch 19 is 0.9007384181022644\nEpoch 19 Val loss: 0.324388325214386\nAccuracy at Epoch 19 is 0.8638399839401245\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"imp = list()\n\ndef hook_function(module, input, output):\n    #set_trace()\n    if not model.training:\n        #set_trace()\n        imp.append(output[0].tolist())","metadata":{"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"#handle.remove()\nfor name, layer in model.named_children():\n    if name == 'sa':\n        for sa_name, sa_layer in layer.named_children():\n            if sa_name == 'softmax':\n                print(sa_name)\n                handle = sa_layer.register_forward_hook(hook_function)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:32.623286Z","iopub.execute_input":"2024-04-07T14:35:32.623583Z","iopub.status.idle":"2024-04-07T14:35:32.633683Z","shell.execute_reply.started":"2024-04-07T14:35:32.623543Z","shell.execute_reply":"2024-04-07T14:35:32.633056Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"softmax\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_text(text):\n    #set_trace()\n    word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n                     if preprocess_string(word) in vocab.keys()])\n    word_seq = np.expand_dims(word_seq,axis=0)\n    pad =  torch.from_numpy(padding_(word_seq,200))\n    inputs = pad.to(device)\n    test_mask = get_masks(inputs).to(device)\n    batch_size = 1\n    model.eval()\n    #set_trace()\n    output = model(inputs, test_mask, train_positional_encoding)\n    output = nn.Sigmoid()(output)\n    return output.item()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:47:57.097493Z","iopub.execute_input":"2024-04-07T14:47:57.097781Z","iopub.status.idle":"2024-04-07T14:47:57.105847Z","shell.execute_reply.started":"2024-04-07T14:47:57.097742Z","shell.execute_reply":"2024-04-07T14:47:57.104948Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# 13000, 14000, 15000, 15100\nindex = 1 \nprint(df['review'][index])\nprint('='*70)\nprint(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\nprint('='*70)\npro = predict_text(df['review'][index])\nstatus = \"positive\" if pro > 0.5 else \"negative\"\npro = (1 - pro) if status == \"negative\" else pro\nprint(f'Predicted sentiment is {status} with a probability of {pro}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:52:25.125525Z","iopub.execute_input":"2024-04-07T14:52:25.125820Z","iopub.status.idle":"2024-04-07T14:52:25.138690Z","shell.execute_reply.started":"2024-04-07T14:52:25.125792Z","shell.execute_reply":"2024-04-07T14:52:25.137780Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"wonderful little production the filming technique unassuming old time bbc fashion gives comforting sometimes discomforting sense realism entire piece the actors extremely well chosen michael sheen has got polari voices pat too truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master comedy life the realism really comes home little things fantasy guard which rather use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell murals decorating every surface terribly well done\n======================================================================\nActual sentiment is  : positive\n======================================================================\nPredicted sentiment is positive with a probability of 0.9721733927726746\n","output_type":"stream"}]},{"cell_type":"code","source":"attn_imp = np.sum(np.array(imp)[0], axis=0)\ncleaned_words = ' '.join([word for word in df.loc[index, 'review'].split() if preprocess_string(word) in vocab.keys()])\n#colors = attn_imp * (255/np.max(attn_imp))\nmaxi = np.max(attn_imp); mini = np.min(attn_imp)\nmax_val, min_val = 255, 0\ncolors = min_val + (max_val - min_val) * (attn_imp - mini) / (maxi - mini)\n\nfor color, word in zip(colors.tolist(), cleaned_words.split()):\n    if int(color) > 0:\n        if int(color) < 50:\n            r, g, b = 255, 255, 255\n            print(f'\\033[48;2;{int(r)};{g};{b}m{word}\\033', end=' ')\n        else:\n            r, g, b = int(color), 0, 0\n            print(f'\\033[48;2;{r};{g};{b}m\\033[97m{word}\\033[0m', end=' ')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:52:28.865427Z","iopub.execute_input":"2024-04-07T14:52:28.865857Z","iopub.status.idle":"2024-04-07T14:52:28.885585Z","shell.execute_reply.started":"2024-04-07T14:52:28.865813Z","shell.execute_reply":"2024-04-07T14:52:28.884573Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"\u001b[48;2;170;0;0m\u001b[97mwonderful\u001b[0m \u001b[48;2;64;0;0m\u001b[97mlittle\u001b[0m \u001b[48;2;53;0;0m\u001b[97mproduction\u001b[0m \u001b[48;2;69;0;0m\u001b[97mfilming\u001b[0m \u001b[48;2;255;255;255mold\u001b \u001b[48;2;56;0;0m\u001b[97mtime\u001b[0m \u001b[48;2;255;255;255mfashion\u001b \u001b[48;2;255;255;255mgives\u001b \u001b[48;2;255;255;255msometimes\u001b \u001b[48;2;61;0;0m\u001b[97msense\u001b[0m \u001b[48;2;255;255;255mrealism\u001b \u001b[48;2;125;0;0m\u001b[97mentire\u001b[0m \u001b[48;2;103;0;0m\u001b[97mpiece\u001b[0m \u001b[48;2;255;255;255mactors\u001b \u001b[48;2;255;255;255mextremely\u001b \u001b[48;2;255;255;255mwell\u001b \u001b[48;2;99;0;0m\u001b[97mmichael\u001b[0m \u001b[48;2;255;255;255mgot\u001b \u001b[48;2;255;255;255mtruly\u001b \u001b[48;2;130;0;0m\u001b[97msee\u001b[0m \u001b[48;2;255;255;255mediting\u001b \u001b[48;2;255;255;255mreferences\u001b \u001b[48;2;255;255;255mwilliams\u001b \u001b[48;2;67;0;0m\u001b[97mwell\u001b[0m \u001b[48;2;255;255;255mworth\u001b \u001b[48;2;59;0;0m\u001b[97mwatching\u001b[0m \u001b[48;2;255;255;255mwritten\u001b \u001b[48;2;255;255;255mpiece\u001b \u001b[48;2;255;255;255mproduction\u001b \u001b[48;2;255;255;255mone\u001b \u001b[48;2;120;0;0m\u001b[97mgreat\u001b[0m \u001b[48;2;61;0;0m\u001b[97mmaster\u001b[0m \u001b[48;2;255;255;255mcomedy\u001b \u001b[48;2;67;0;0m\u001b[97mlife\u001b[0m \u001b[48;2;255;255;255mrealism\u001b \u001b[48;2;57;0;0m\u001b[97mreally\u001b[0m \u001b[48;2;64;0;0m\u001b[97mcomes\u001b[0m \u001b[48;2;255;255;255mhome\u001b \u001b[48;2;81;0;0m\u001b[97mlittle\u001b[0m \u001b[48;2;255;255;255mthings\u001b \u001b[48;2;255;255;255mfantasy\u001b \u001b[48;2;255;255;255mrather\u001b \u001b[48;2;255;255;255muse\u001b \u001b[48;2;255;255;255mdream\u001b \u001b[48;2;255;255;255mremains\u001b \u001b[48;2;254;0;0m\u001b[97msolid\u001b[0m \u001b[48;2;255;255;255mplays\u001b \u001b[48;2;69;0;0m\u001b[97mknowledge\u001b[0m \u001b[48;2;255;255;255mparticularly\u001b \u001b[48;2;255;255;255mscenes\u001b \u001b[48;2;255;255;255msets\u001b \u001b[48;2;69;0;0m\u001b[97mparticularly\u001b[0m \u001b[48;2;121;0;0m\u001b[97mflat\u001b[0m \u001b[48;2;255;255;255mevery\u001b \u001b[48;2;165;0;0m\u001b[97mterribly\u001b[0m \u001b[48;2;76;0;0m\u001b[97mwell\u001b[0m \u001b[48;2;255;255;255mdone\u001b ","output_type":"stream"}]},{"cell_type":"code","source":"dummy = pd.read_csv(base_csv)\ndummy['review'][index]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:52:35.208746Z","iopub.execute_input":"2024-04-07T14:52:35.209271Z","iopub.status.idle":"2024-04-07T14:52:35.784035Z","shell.execute_reply.started":"2024-04-07T14:52:35.209225Z","shell.execute_reply":"2024-04-07T14:52:35.783184Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"},"metadata":{}}]},{"cell_type":"code","source":"for r in list(range(160, 255, 5)):\n    #print(f'\\033[48;5;{r};1;1mthis\\033')\n    #print(f'\\033[48;5;{r}mthis\\033')\n    gb = 40\n    print(f'\\033[48;2;{r};{gb};{gb}mthis {r}\\033')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:32.935724Z","iopub.status.idle":"2024-04-07T14:35:32.936154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxi = np.max(attn_imp); mini = np.min(attn_imp)\nmax_val, min_val = 255, 0\nprint(min_val, max_val)\nprint(mini, maxi)\n\nmin_val + (max_val - min_val) * (attn_imp - mini) / (maxi - mini)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:32.937163Z","iopub.status.idle":"2024-04-07T14:35:32.937583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scale_array(array, min_value, max_value):\n    min_array_value = min(array)\n    max_array_value = max(array)\n    scaled_array = []\n    print(min_value, max_value)\n    print(min_array_value, max_array_value)\n    scaled_value = min_value + (max_value - min_value) * (array - min_array_value) / (max_array_value - min_array_value)\n#     for value in array:\n#         scaled_value = min_value + (max_value - min_value) * (value - min_array_value) / (max_array_value - min_array_value)\n#         scaled_array.append(scaled_value)\n\n    return scaled_value\n\n# Example usage\narray = attn_imp\nmin_value = 0\nmax_value = 255\n\nscaled_array = scale_array(array, min_value, max_value)\nprint(scaled_array)  # Output: [0.0, 25.0, 50.0, 75.0, 100.0]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:35:32.938590Z","iopub.status.idle":"2024-04-07T14:35:32.939124Z"},"trusted":true},"execution_count":null,"outputs":[]}]}