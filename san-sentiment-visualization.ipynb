{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":29869,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport torch.optim as optim\nfrom IPython.core.debugger import set_trace\nfrom collections import Counter\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.data.utils import get_tokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T06:25:18.987705Z","iopub.execute_input":"2024-04-07T06:25:18.987984Z","iopub.status.idle":"2024-04-07T06:25:18.995903Z","shell.execute_reply.started":"2024-04-07T06:25:18.987957Z","shell.execute_reply":"2024-04-07T06:25:18.995107Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\n\n# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")\n      \nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:23:53.467389Z","iopub.execute_input":"2024-04-07T06:23:53.467702Z","iopub.status.idle":"2024-04-07T06:23:53.539365Z","shell.execute_reply.started":"2024-04-07T06:23:53.467666Z","shell.execute_reply":"2024-04-07T06:23:53.538651Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"GPU is available\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"base_csv = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'\ndf = pd.read_csv(base_csv)\ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-04-07T06:23:53.540802Z","iopub.execute_input":"2024-04-07T06:23:53.541092Z","iopub.status.idle":"2024-04-07T06:23:54.686458Z","shell.execute_reply.started":"2024-04-07T06:23:53.541057Z","shell.execute_reply":"2024-04-07T06:23:54.685562Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Analysing sentiment","metadata":{}},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"stop_words = list(set(stopwords.words('english')))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:25:23.753089Z","iopub.execute_input":"2024-04-07T06:25:23.753368Z","iopub.status.idle":"2024-04-07T06:25:23.757861Z","shell.execute_reply.started":"2024-04-07T06:25:23.753340Z","shell.execute_reply":"2024-04-07T06:25:23.757075Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def preprocess_string(s):\n    s = s.lower()\n    s = ' '.join([word for word in s.split() if word not in stop_words])\n    # replace <br /><br /> with nothing\n    s = re.sub('<[^>]+>', '', s)\n    # Remove all non-word characters (everything except numbers and letters)\n    s = re.sub(r\"[^\\w\\s]\", ' ', s)\n    # Replace all runs of whitespaces with no space\n    s = re.sub(r\"\\s+\", ' ', s)\n    # replace digits with no space\n    s = re.sub(r\"\\d\", '', s)\n    \n    # remove single characters\n    s = ' '.join(list(filter(lambda x: len(x)!=1, s.split())))\n    \n\n    return s","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:25:38.533548Z","iopub.execute_input":"2024-04-07T06:25:38.533845Z","iopub.status.idle":"2024-04-07T06:25:38.541312Z","shell.execute_reply.started":"2024-04-07T06:25:38.533812Z","shell.execute_reply":"2024-04-07T06:25:38.540596Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df.loc[:, 'review'] = df.loc[:, 'review'].apply(preprocess_string)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:25:41.563249Z","iopub.execute_input":"2024-04-07T06:25:41.563548Z","iopub.status.idle":"2024-04-07T06:26:06.229282Z","shell.execute_reply.started":"2024-04-07T06:25:41.563506Z","shell.execute_reply":"2024-04-07T06:26:06.228611Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:00.143695Z","iopub.execute_input":"2024-04-07T06:28:00.143979Z","iopub.status.idle":"2024-04-07T06:28:00.153259Z","shell.execute_reply.started":"2024-04-07T06:28:00.143952Z","shell.execute_reply":"2024-04-07T06:28:00.152635Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  one reviewers mentioned watching oz episode ho...  positive\n1  wonderful little production filming technique ...  positive\n2  thought wonderful way spend time hot summer we...  positive\n3  basically family little boy jake thinks zombie...  negative\n4  petter mattei love time money visually stunnin...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewers mentioned watching oz episode ho...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production filming technique ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically family little boy jake thinks zombie...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei love time money visually stunnin...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"complete = ' '.join(df['review'].tolist()).split()\ncounter = Counter(complete)\n# words like could, would could be removed.\nmost_occur = counter.most_common(4)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:06.063481Z","iopub.execute_input":"2024-04-07T06:28:06.063799Z","iopub.status.idle":"2024-04-07T06:28:07.841548Z","shell.execute_reply.started":"2024-04-07T06:28:06.063765Z","shell.execute_reply":"2024-04-07T06:28:07.840787Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"counter.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:15.103644Z","iopub.execute_input":"2024-04-07T06:28:15.103946Z","iopub.status.idle":"2024-04-07T06:28:15.139971Z","shell.execute_reply.started":"2024-04-07T06:28:15.103913Z","shell.execute_reply":"2024-04-07T06:28:15.139312Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[('movie', 87935),\n ('film', 79675),\n ('one', 53585),\n ('like', 40160),\n ('good', 29737),\n ('time', 25099),\n ('even', 24856),\n ('would', 24599),\n ('story', 23108),\n ('really', 23089)]"},"metadata":{}}]},{"cell_type":"code","source":"X,y = df['review'].values,df['sentiment'].values\nx_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\nprint(f'shape of train data is {x_train.shape}')\nprint(f'shape of test data is {x_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:19.227995Z","iopub.execute_input":"2024-04-07T06:28:19.228264Z","iopub.status.idle":"2024-04-07T06:28:19.320532Z","shell.execute_reply.started":"2024-04-07T06:28:19.228237Z","shell.execute_reply":"2024-04-07T06:28:19.319661Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"shape of train data is (37500,)\nshape of test data is (12500,)\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:24:59.063136Z","iopub.execute_input":"2024-04-07T06:24:59.063423Z","iopub.status.idle":"2024-04-07T06:24:59.068464Z","shell.execute_reply.started":"2024-04-07T06:24:59.063391Z","shell.execute_reply":"2024-04-07T06:24:59.067602Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'ohhh man talking about far bad cheesy horror flicks go movie truly class own real gem first off film originally english that okay voice dubbing truly exceptional favorite excerpt dialog and plenty came from feeling little better thirsty blood and drama play play recap interaction military scientists scene scientist you can it ll disaster military officer that science fiction he proceeds cause complete disaster like scientist predicted scene scientist if many people die military officer you know talking about he many people die scene scientist don it ll kill everyone military officer that nonsense he proceeds kill everyone scene you get idea if enough scenes really stood instant classics one scene military literally guys pointing guns two unarmed men leader yells go get em army guys one time drop guns fist fight two adversaries instant classic and worry attention detail left out movie even hip upbeat keyboard synth soundtrack set mood and trust realize review might contain spoilers many goodies epic really scratched surface movie caliber comes decade true movie watching experience masterpiece wow'"},"metadata":{}}]},{"cell_type":"code","source":"def tockenize(x_train,y_train,x_val,y_val):\n    word_list = []\n\n    stop_words = set(stopwords.words('english')) \n    for sent in x_train:\n        for word in sent.lower().split():\n            word = preprocess_string(word)\n            if word not in stop_words and word != '':\n                word_list.append(word)\n  \n    corpus = Counter(word_list)\n    # sorting on the basis of most common words\n    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n    # creating a dict\n    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n    \n    # tockenize\n    final_list_train,final_list_test = [],[]\n    for sent in x_train:\n            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                     if preprocess_string(word) in onehot_dict.keys()])\n    for sent in x_val:\n            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                    if preprocess_string(word) in onehot_dict.keys()])\n            \n    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:21.742659Z","iopub.execute_input":"2024-04-07T06:28:21.742940Z","iopub.status.idle":"2024-04-07T06:28:21.756196Z","shell.execute_reply.started":"2024-04-07T06:28:21.742913Z","shell.execute_reply":"2024-04-07T06:28:21.755430Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:24.343597Z","iopub.execute_input":"2024-04-07T06:28:24.343882Z","iopub.status.idle":"2024-04-07T06:31:25.714753Z","shell.execute_reply.started":"2024-04-07T06:28:24.343854Z","shell.execute_reply":"2024-04-07T06:31:25.713976Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(f'Length of vocabulary is {len(vocab)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:31:52.228065Z","iopub.execute_input":"2024-04-07T06:31:52.228369Z","iopub.status.idle":"2024-04-07T06:31:52.232239Z","shell.execute_reply.started":"2024-04-07T06:31:52.228330Z","shell.execute_reply":"2024-04-07T06:31:52.231485Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Length of vocabulary is 1000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Analysing review length","metadata":{}},{"cell_type":"code","source":"rev_len = [len(i) for i in x_train]\npd.Series(rev_len).hist()\nplt.show()\npd.Series(rev_len).describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:31:54.833024Z","iopub.execute_input":"2024-04-07T06:31:54.833287Z","iopub.status.idle":"2024-04-07T06:31:55.055044Z","shell.execute_reply.started":"2024-04-07T06:31:54.833262Z","shell.execute_reply":"2024-04-07T06:31:55.054244Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"count    37500.000000\nmean        67.457253\nstd         46.671170\nmin          2.000000\n25%         38.000000\n50%         53.000000\n75%         82.000000\nmax        619.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"def padding_(sentences, seq_len):\n    features = np.zeros((len(sentences), seq_len),dtype=int)\n    for ii, review in enumerate(sentences):\n        if len(review) != 0:\n            #features[ii, -len(review):] = np.array(review)[:seq_len]\n            features[ii, :len(review)] = np.array(review)[:seq_len]\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:00.802559Z","iopub.execute_input":"2024-04-07T06:32:00.802834Z","iopub.status.idle":"2024-04-07T06:32:00.809203Z","shell.execute_reply.started":"2024-04-07T06:32:00.802808Z","shell.execute_reply":"2024-04-07T06:32:00.808475Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#we have very less number of reviews with length > 500.\n#So we will consideronly those below it.\nx_train_pad = torch.tensor(padding_(x_train,100))\nx_test_pad = torch.tensor(padding_(x_test,100))\nx_train_pad.shape, x_test_pad.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:02.631859Z","iopub.execute_input":"2024-04-07T06:32:02.632162Z","iopub.status.idle":"2024-04-07T06:32:03.491044Z","shell.execute_reply.started":"2024-04-07T06:32:02.632129Z","shell.execute_reply":"2024-04-07T06:32:03.490343Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(torch.Size([37500, 100]), torch.Size([12500, 100]))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_pad[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:06.183202Z","iopub.execute_input":"2024-04-07T06:32:06.183509Z","iopub.status.idle":"2024-04-07T06:32:06.202122Z","shell.execute_reply.started":"2024-04-07T06:32:06.183475Z","shell.execute_reply":"2024-04-07T06:32:06.201492Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"tensor([132, 177,   2, 285, 226,  87, 556, 385, 522, 203, 293, 890,  32, 279,\n         20, 558,  29,  11, 356,  38,  16, 905,  19,  79,  19,  11, 476, 830,\n         41,  21,  80, 379,  41, 476, 346,  83, 242, 545,  55, 107,  93,   5,\n        108, 153, 826, 265,  55,   7, 505, 242,  73, 844, 111, 428,  49, 214,\n         32, 174, 156,   4,  21, 145, 204, 108,  72,  80,   3, 428,  48, 772,\n         64, 407, 514, 104, 830, 809,  87, 282, 356, 251, 295, 243, 348,   5,\n         56,   4,  39,  23, 284,  90,  46,  90,  14,  79,   2,  13, 192, 179,\n         33, 291])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"def get_masks(padded):\n    B, T = padded.shape\n    mask = torch.eq(padded, 0).to(torch.float32)\n    mask = mask * -1e9\n    masked_reshape = mask.reshape(B, 1, T)\n    return masked_reshape\n\ntrain_mask = get_masks(x_train_pad)\nval_mask = get_masks(x_test_pad)\nprint(train_mask.shape, val_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:12.017796Z","iopub.execute_input":"2024-04-07T06:32:12.018217Z","iopub.status.idle":"2024-04-07T06:32:12.050221Z","shell.execute_reply.started":"2024-04-07T06:32:12.018179Z","shell.execute_reply":"2024-04-07T06:32:12.049288Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"torch.Size([37500, 1, 100]) torch.Size([12500, 1, 100])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_angle(timesteps, dim):\n    k = np.arange(dim)[np.newaxis, :]\n    i = k // 2\n\n    positions = np.arange(timesteps)[:, np.newaxis]\n    angles = positions / (10000 ** (2*i/dim))\n\n    return angles\n\ndef get_positional_embeddings(angles):\n    angles[:, 0::2] = np.sin(angles[:, 0::2])\n    angles[:, 1::2] = np.cos(angles[:, 1::2])\n\n    return torch.tensor(angles, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:12.297587Z","iopub.execute_input":"2024-04-07T06:32:12.297858Z","iopub.status.idle":"2024-04-07T06:32:12.305675Z","shell.execute_reply.started":"2024-04-07T06:32:12.297832Z","shell.execute_reply":"2024-04-07T06:32:12.304718Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:13.023645Z","iopub.execute_input":"2024-04-07T06:32:13.023943Z","iopub.status.idle":"2024-04-07T06:32:13.029615Z","shell.execute_reply.started":"2024-04-07T06:32:13.023914Z","shell.execute_reply":"2024-04-07T06:32:13.028656Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        self.softmax = nn.Softmax(dim=-1)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = self.softmax(wei)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:13.031413Z","iopub.execute_input":"2024-04-07T06:32:13.031762Z","iopub.status.idle":"2024-04-07T06:32:13.041426Z","shell.execute_reply.started":"2024-04-07T06:32:13.031728Z","shell.execute_reply":"2024-04-07T06:32:13.040739Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.sa = Head(head_size)\n        self.avgpool = nn.AvgPool1d(timesteps)\n        self.inter1_layer = nn.Linear(head_size, head_size)\n        self.output = nn.Linear(head_size, output)\n        \n    def forward(self, x, mask, positional_encoding):\n        B, T = x.shape # validation shape --> (1000, 73)\n#         print(self.embedding(x).shape, positional_encoding.shape)\n        #set_trace()\n        embedding = self.embedding(x) + positional_encoding # (B, timesteps, n_embed)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size)\n        averaged = self.avgpool(sa_out.permute(0, 2, 1)) # (B, head_size, 1)\n        # implement average pooling after sa_out\n        inter1 = self.inter1_layer(averaged.view(B, -1)) # (B, head_size) @ (head_size, head_size) --> (B, headsize)\n        output = self.output(inter1) # (B, head_size) @ (head_size, output) --> (B, output)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:42:18.752904Z","iopub.execute_input":"2024-04-07T07:42:18.753206Z","iopub.status.idle":"2024-04-07T07:42:18.762867Z","shell.execute_reply.started":"2024-04-07T07:42:18.753172Z","shell.execute_reply":"2024-04-07T07:42:18.761994Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, mask, y_batch, positional_encoding):\n    optimizer.zero_grad()\n    output = model(x_batch, mask, positional_encoding)\n    #set_trace()\n    output = nn.Sigmoid()(output)\n    \n    \n    loss = loss_function(output.view(-1), y_batch.view(-1))\n    \n    correct = 0\n    correct += ((output.view(-1) > 0.5).float() == y_batch).float().sum()\n    accuracy = correct / y_batch.shape[0]\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:40:32.462821Z","iopub.execute_input":"2024-04-07T07:40:32.463101Z","iopub.status.idle":"2024-04-07T07:40:32.470167Z","shell.execute_reply.started":"2024-04-07T07:40:32.463074Z","shell.execute_reply":"2024-04-07T07:40:32.469452Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"n_embed = 32\ntimesteps = x_train_pad.shape[-1]\nbatch_size = 256\nbatch_per_epoch = x_train_pad.shape[0] // batch_size\n\ntrain_padded, train_y = x_train_pad.to(device).long(), torch.tensor(y_train, dtype=torch.float).to(device)\nval_padded, val_y = x_test_pad.to(device).long(), torch.tensor(y_test, dtype=torch.float).to(device) \ntrain_mask, val_mask = train_mask.to(device), val_mask.to(device)\ntrain_positional_encoding = get_positional_embeddings(get_angle(timesteps, n_embed)).to(device)\nval_positional_encoding = get_positional_embeddings(get_angle(val_padded.shape[-1], n_embed)).to(device)\nprint('Shape of encodings are', train_positional_encoding.shape, val_positional_encoding.shape)\n\n\nmodel = Encoder(len(vocab)+1, n_embed, timesteps, head_size=n_embed, output=1).to(device)\n\nloss_function = nn.BCELoss()\n#loss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n\n#model = nn.DataParallel(model, list(range(torch.cuda.device_count())))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:44:12.122723Z","iopub.execute_input":"2024-04-07T07:44:12.122985Z","iopub.status.idle":"2024-04-07T07:44:12.146829Z","shell.execute_reply.started":"2024-04-07T07:44:12.122959Z","shell.execute_reply":"2024-04-07T07:44:12.146091Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Shape of encodings are torch.Size([100, 32]) torch.Size([100, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_accuracy(outputs, labels):\n    correct = 0\n    #correct += (torch.argmax(F.softmax(outputs, dim=-1), dim=-1) == labels).float().sum()\n    correct += ((outputs.view(-1) > 0.5).float() == labels).float().sum()\n    return correct / labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:18.043026Z","iopub.execute_input":"2024-04-07T06:32:18.043251Z","iopub.status.idle":"2024-04-07T06:32:18.048095Z","shell.execute_reply.started":"2024-04-07T06:32:18.043226Z","shell.execute_reply":"2024-04-07T06:32:18.047233Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0, 20):\n    train_loss, val_loss = 0, 0\n    training_accuracy = 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = train_padded[start:start+batch_size], train_y[start:start+batch_size], train_mask[start:start+batch_size]\n#         x_batch, y_batch, mask = x_batch.to(device).long(), y_batch.to(device).long(), mask.to(device).long()\n\n        model.train(True)\n    \n        loss, accuracy = train_epoch(x_batch, mask, y_batch, train_positional_encoding)\n        train_loss += loss\n        training_accuracy += accuracy\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')\n    print(f'Accuracy at Epoch {epoch} is {training_accuracy / (batch_per_epoch)}')\n    \n    model.eval()\n    with torch.no_grad():\n        output_val = model(val_padded, val_mask, val_positional_encoding)\n        output_val = nn.Sigmoid()(output_val)\n        \n        loss_val = loss_function(output_val.view(-1), val_y.view(-1))\n        \n        accuracy = calculate_accuracy(output_val, val_y)\n        \n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        print(f'Accuracy at Epoch {epoch} is {accuracy}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:44:18.077965Z","iopub.execute_input":"2024-04-07T07:44:18.078316Z","iopub.status.idle":"2024-04-07T07:44:31.560280Z","shell.execute_reply.started":"2024-04-07T07:44:18.078281Z","shell.execute_reply":"2024-04-07T07:44:31.559462Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Epoch 0 Loss: 0.6238114237785339\nAccuracy at Epoch 0 is 0.6479558944702148\nEpoch 0 Val loss: 0.5718191266059875\nAccuracy at Epoch 0 is 0.7010399699211121\n\nEpoch 1 Loss: 0.5379121899604797\nAccuracy at Epoch 1 is 0.7301744222640991\nEpoch 1 Val loss: 0.5053843259811401\nAccuracy at Epoch 1 is 0.7503199577331543\n\nEpoch 2 Loss: 0.45939385890960693\nAccuracy at Epoch 2 is 0.7803670763969421\nEpoch 2 Val loss: 0.435458779335022\nAccuracy at Epoch 2 is 0.7954399585723877\n\nEpoch 3 Loss: 0.40997064113616943\nAccuracy at Epoch 3 is 0.8124464750289917\nEpoch 3 Val loss: 0.4054807126522064\nAccuracy at Epoch 3 is 0.8119999766349792\n\nEpoch 4 Loss: 0.3834429383277893\nAccuracy at Epoch 4 is 0.8284193277359009\nEpoch 4 Val loss: 0.3865524232387543\nAccuracy at Epoch 4 is 0.825439989566803\n\nEpoch 5 Loss: 0.36474302411079407\nAccuracy at Epoch 5 is 0.8374893069267273\nEpoch 5 Val loss: 0.3741079270839691\nAccuracy at Epoch 5 is 0.8336799740791321\n\nEpoch 6 Loss: 0.35168445110321045\nAccuracy at Epoch 6 is 0.8446864485740662\nEpoch 6 Val loss: 0.36646750569343567\nAccuracy at Epoch 6 is 0.837119996547699\n\nEpoch 7 Loss: 0.34233999252319336\nAccuracy at Epoch 7 is 0.849609375\nEpoch 7 Val loss: 0.36099687218666077\nAccuracy at Epoch 7 is 0.8394399881362915\n\nEpoch 8 Loss: 0.3347398042678833\nAccuracy at Epoch 8 is 0.8523383736610413\nEpoch 8 Val loss: 0.356601357460022\nAccuracy at Epoch 8 is 0.8418399691581726\n\nEpoch 9 Loss: 0.32831722497940063\nAccuracy at Epoch 9 is 0.8556827902793884\nEpoch 9 Val loss: 0.3538395166397095\nAccuracy at Epoch 9 is 0.8441599607467651\n\nEpoch 10 Loss: 0.32297483086586\nAccuracy at Epoch 10 is 0.8585188388824463\nEpoch 10 Val loss: 0.3523835837841034\nAccuracy at Epoch 10 is 0.8447999954223633\n\nEpoch 11 Loss: 0.3181610703468323\nAccuracy at Epoch 11 is 0.860418438911438\nEpoch 11 Val loss: 0.3516394793987274\nAccuracy at Epoch 11 is 0.8459199666976929\n\nEpoch 12 Loss: 0.3136061131954193\nAccuracy at Epoch 12 is 0.86328125\nEpoch 12 Val loss: 0.35140055418014526\nAccuracy at Epoch 12 is 0.8466399908065796\n\nEpoch 13 Loss: 0.30907076597213745\nAccuracy at Epoch 13 is 0.8658497333526611\nEpoch 13 Val loss: 0.3514809310436249\nAccuracy at Epoch 13 is 0.8481599688529968\n\nEpoch 14 Loss: 0.30441099405288696\nAccuracy at Epoch 14 is 0.868364691734314\nEpoch 14 Val loss: 0.35189899802207947\nAccuracy at Epoch 14 is 0.8478399515151978\n\nEpoch 15 Loss: 0.2999838888645172\nAccuracy at Epoch 15 is 0.8703981041908264\nEpoch 15 Val loss: 0.3527916669845581\nAccuracy at Epoch 15 is 0.8475199937820435\n\nEpoch 16 Loss: 0.2959911823272705\nAccuracy at Epoch 16 is 0.8723779916763306\nEpoch 16 Val loss: 0.3541907072067261\nAccuracy at Epoch 16 is 0.8479999899864197\n\nEpoch 17 Loss: 0.2922394573688507\nAccuracy at Epoch 17 is 0.8741170763969421\nEpoch 17 Val loss: 0.3559161424636841\nAccuracy at Epoch 17 is 0.8479999899864197\n\nEpoch 18 Loss: 0.2885853052139282\nAccuracy at Epoch 18 is 0.8763377666473389\nEpoch 18 Val loss: 0.35788780450820923\nAccuracy at Epoch 18 is 0.8481599688529968\n\nEpoch 19 Loss: 0.2849632501602173\nAccuracy at Epoch 19 is 0.8783978819847107\nEpoch 19 Val loss: 0.36009538173675537\nAccuracy at Epoch 19 is 0.8479200005531311\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"imp = list()\n\ndef hook_function(module, input, output):\n    #set_trace()\n    if not model.training:\n        #set_trace()\n        imp.append(output[0].tolist())","metadata":{"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"#handle.remove()\nfor name, layer in model.named_children():\n    if name == 'sa':\n        for sa_name, sa_layer in layer.named_children():\n            if sa_name == 'softmax':\n                print(sa_name)\n                handle = sa_layer.register_forward_hook(hook_function)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:46:42.483744Z","iopub.execute_input":"2024-04-07T07:46:42.484024Z","iopub.status.idle":"2024-04-07T07:46:42.489846Z","shell.execute_reply.started":"2024-04-07T07:46:42.483997Z","shell.execute_reply":"2024-04-07T07:46:42.489154Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"softmax\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_text(text):\n    #set_trace()\n    word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n                     if preprocess_string(word) in vocab.keys()])\n    word_seq = np.expand_dims(word_seq,axis=0)\n    pad =  torch.from_numpy(padding_(word_seq,100))\n    inputs = pad.to(device)\n    test_mask = get_masks(inputs).to(device)\n    batch_size = 1\n    model.eval()\n    output = model(inputs, test_mask, train_positional_encoding)\n    output = nn.Sigmoid()(output)\n    return output.item()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:46:44.662938Z","iopub.execute_input":"2024-04-07T07:46:44.663206Z","iopub.status.idle":"2024-04-07T07:46:44.671082Z","shell.execute_reply.started":"2024-04-07T07:46:44.663179Z","shell.execute_reply":"2024-04-07T07:46:44.670255Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# 13000, 14000, 15000\nindex = 15100 \nprint(df['review'][index])\nprint('='*70)\nprint(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\nprint('='*70)\npro = predict_text(df['review'][index])\nstatus = \"positive\" if pro > 0.5 else \"negative\"\npro = (1 - pro) if status == \"negative\" else pro\nprint(f'Predicted sentiment is {status} with a probability of {pro}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:48:58.862619Z","iopub.execute_input":"2024-04-07T07:48:58.862928Z","iopub.status.idle":"2024-04-07T07:48:58.875653Z","shell.execute_reply.started":"2024-04-07T07:48:58.862894Z","shell.execute_reply":"2024-04-07T07:48:58.874581Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"used fascination cartoon back college made much charm get smart admittedly faults rather enjoyable naturally interested seeing film version saw afterwords wished never made besides miscast around earth though broderick even close role make grade effects reasonable perhaps thing liked movie seeing live action version gadgets action missing story treatment made funny charming interesting original wacky cartoon lighthearted attitude fun motion picture became murky took far seriously seriously great plot went crazy enough make seem like cartoon film might enjoyable exists deserve considered part gadget legacy\n======================================================================\nActual sentiment is  : negative\n======================================================================\nPredicted sentiment is positive with a probability of 0.6932033896446228\n","output_type":"stream"}]},{"cell_type":"code","source":"attn_imp = np.sum(np.array(imp)[0], axis=0)\ncleaned_words = ' '.join([word for word in df.loc[index, 'review'].split() if preprocess_string(word) in vocab.keys()])\n#colors = attn_imp * (255/np.max(attn_imp))\nmaxi = np.max(attn_imp); mini = np.min(attn_imp)\nmax_val, min_val = 255, 0\ncolors = min_val + (max_val - min_val) * (attn_imp - mini) / (maxi - mini)\n\nfor color, word in zip(colors.tolist(), cleaned_words.split()):\n    if int(color) > 0:\n        if int(color) < 30:\n            r, g, b = 255, 255, 255\n            print(f'\\033[48;2;{int(r)};{g};{b}m{word}\\033', end=' ')\n        else:\n            r, g, b = int(color), 0, 0\n            print(f'\\033[48;2;{r};{g};{b}m\\033[97m{word}\\033[0m', end=' ')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:50:55.704722Z","iopub.execute_input":"2024-04-07T08:50:55.704993Z","iopub.status.idle":"2024-04-07T08:50:55.720760Z","shell.execute_reply.started":"2024-04-07T08:50:55.704967Z","shell.execute_reply":"2024-04-07T08:50:55.719728Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"\u001b[48;2;255;255;255mused\u001b \u001b[48;2;197;0;0m\u001b[97mcartoon\u001b[0m \u001b[48;2;40;0;0m\u001b[97mback\u001b[0m \u001b[48;2;255;255;255mcollege\u001b \u001b[48;2;68;0;0m\u001b[97mmade\u001b[0m \u001b[48;2;255;255;255mmuch\u001b \u001b[48;2;255;255;255mget\u001b \u001b[48;2;112;0;0m\u001b[97mrather\u001b[0m \u001b[48;2;39;0;0m\u001b[97menjoyable\u001b[0m \u001b[48;2;40;0;0m\u001b[97minterested\u001b[0m \u001b[48;2;54;0;0m\u001b[97mseeing\u001b[0m \u001b[48;2;255;255;255mfilm\u001b \u001b[48;2;255;255;255mversion\u001b \u001b[48;2;79;0;0m\u001b[97msaw\u001b[0m \u001b[48;2;255;255;255mnever\u001b \u001b[48;2;82;0;0m\u001b[97mmade\u001b[0m \u001b[48;2;255;255;255maround\u001b \u001b[48;2;75;0;0m\u001b[97mearth\u001b[0m \u001b[48;2;255;255;255mthough\u001b \u001b[48;2;83;0;0m\u001b[97meven\u001b[0m \u001b[48;2;255;255;255mclose\u001b \u001b[48;2;255;255;255mrole\u001b \u001b[48;2;52;0;0m\u001b[97mmake\u001b[0m \u001b[48;2;255;255;255meffects\u001b \u001b[48;2;56;0;0m\u001b[97mperhaps\u001b[0m \u001b[48;2;255;255;255mthing\u001b \u001b[48;2;55;0;0m\u001b[97mliked\u001b[0m \u001b[48;2;77;0;0m\u001b[97mmovie\u001b[0m \u001b[48;2;255;255;255mseeing\u001b \u001b[48;2;255;0;0m\u001b[97mlive\u001b[0m \u001b[48;2;74;0;0m\u001b[97maction\u001b[0m \u001b[48;2;47;0;0m\u001b[97mversion\u001b[0m \u001b[48;2;101;0;0m\u001b[97maction\u001b[0m \u001b[48;2;86;0;0m\u001b[97mmissing\u001b[0m \u001b[48;2;55;0;0m\u001b[97mstory\u001b[0m \u001b[48;2;87;0;0m\u001b[97mmade\u001b[0m \u001b[48;2;255;255;255mfunny\u001b \u001b[48;2;255;255;255minteresting\u001b \u001b[48;2;55;0;0m\u001b[97moriginal\u001b[0m \u001b[48;2;45;0;0m\u001b[97mcartoon\u001b[0m \u001b[48;2;93;0;0m\u001b[97mfun\u001b[0m \u001b[48;2;255;255;255mpicture\u001b \u001b[48;2;255;255;255mbecame\u001b \u001b[48;2;100;0;0m\u001b[97mtook\u001b[0m \u001b[48;2;30;0;0m\u001b[97mfar\u001b[0m \u001b[48;2;255;255;255mseriously\u001b \u001b[48;2;255;255;255mseriously\u001b \u001b[48;2;173;0;0m\u001b[97mgreat\u001b[0m \u001b[48;2;255;255;255mplot\u001b \u001b[48;2;38;0;0m\u001b[97mwent\u001b[0m \u001b[48;2;102;0;0m\u001b[97mcrazy\u001b[0m \u001b[48;2;90;0;0m\u001b[97menough\u001b[0m \u001b[48;2;68;0;0m\u001b[97mmake\u001b[0m \u001b[48;2;255;255;255mseem\u001b \u001b[48;2;255;255;255mlike\u001b \u001b[48;2;32;0;0m\u001b[97mcartoon\u001b[0m \u001b[48;2;255;255;255mfilm\u001b \u001b[48;2;74;0;0m\u001b[97mmight\u001b[0m \u001b[48;2;127;0;0m\u001b[97menjoyable\u001b[0m \u001b[48;2;255;255;255mpart\u001b ","output_type":"stream"}]},{"cell_type":"code","source":"for r in list(range(160, 255, 5)):\n    #print(f'\\033[48;5;{r};1;1mthis\\033')\n    #print(f'\\033[48;5;{r}mthis\\033')\n    gb = 40\n    print(f'\\033[48;2;{r};{gb};{gb}mthis {r}\\033')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:54:55.848408Z","iopub.execute_input":"2024-04-07T07:54:55.848692Z","iopub.status.idle":"2024-04-07T07:54:55.854214Z","shell.execute_reply.started":"2024-04-07T07:54:55.848664Z","shell.execute_reply":"2024-04-07T07:54:55.853494Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"\u001b[48;2;160;40;40mthis 160\u001b\n\u001b[48;2;165;40;40mthis 165\u001b\n\u001b[48;2;170;40;40mthis 170\u001b\n\u001b[48;2;175;40;40mthis 175\u001b\n\u001b[48;2;180;40;40mthis 180\u001b\n\u001b[48;2;185;40;40mthis 185\u001b\n\u001b[48;2;190;40;40mthis 190\u001b\n\u001b[48;2;195;40;40mthis 195\u001b\n\u001b[48;2;200;40;40mthis 200\u001b\n\u001b[48;2;205;40;40mthis 205\u001b\n\u001b[48;2;210;40;40mthis 210\u001b\n\u001b[48;2;215;40;40mthis 215\u001b\n\u001b[48;2;220;40;40mthis 220\u001b\n\u001b[48;2;225;40;40mthis 225\u001b\n\u001b[48;2;230;40;40mthis 230\u001b\n\u001b[48;2;235;40;40mthis 235\u001b\n\u001b[48;2;240;40;40mthis 240\u001b\n\u001b[48;2;245;40;40mthis 245\u001b\n\u001b[48;2;250;40;40mthis 250\u001b\n","output_type":"stream"}]},{"cell_type":"code","source":"maxi = np.max(attn_imp); mini = np.min(attn_imp)\nmax_val, min_val = 255, 0\nprint(min_val, max_val)\nprint(mini, maxi)\n\nmin_val + (max_val - min_val) * (attn_imp - mini) / (maxi - mini)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:37:00.252898Z","iopub.execute_input":"2024-04-07T08:37:00.253195Z","iopub.status.idle":"2024-04-07T08:37:00.262989Z","shell.execute_reply.started":"2024-04-07T08:37:00.253162Z","shell.execute_reply":"2024-04-07T08:37:00.262090Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"0 255\n0.0 8.013932260901383\n","output_type":"stream"},{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"array([  9.68326314, 197.68982259,  40.12985196,  12.66820278,\n        68.86362339,   9.33527945,   3.83375762, 112.47360991,\n        39.16424706,  40.18432026,  54.18590521,  14.13333287,\n        26.16636852,  79.30471863,  14.07612639,  82.15585207,\n         2.33640122,  75.38474176,  10.87797196,  83.64628826,\n        22.03394664,   2.95587944,  52.08846202,  25.0849615 ,\n        56.69823381,   1.26216706,  55.66771688,  77.37183633,\n        21.70301173, 255.        ,  74.89097646,  47.50146237,\n       101.66596611,  86.3920809 ,  55.48171939,  87.88707411,\n        19.46120371,  12.62414612,  55.55464479,  45.15891845,\n        93.08070729,   9.13373733,   8.76981857, 100.63251284,\n        30.86249149,  12.94030778,  10.56541555, 173.63062858,\n         9.35418541,  38.20066011, 102.62804108,  90.32881544,\n        68.73708077,  26.00578948,   9.73002099,  32.48192761,\n        21.69000828,  74.13839339, 127.43331457,   8.83658373,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ])"},"metadata":{}}]},{"cell_type":"code","source":"def scale_array(array, min_value, max_value):\n    min_array_value = min(array)\n    max_array_value = max(array)\n    scaled_array = []\n    print(min_value, max_value)\n    print(min_array_value, max_array_value)\n    scaled_value = min_value + (max_value - min_value) * (array - min_array_value) / (max_array_value - min_array_value)\n#     for value in array:\n#         scaled_value = min_value + (max_value - min_value) * (value - min_array_value) / (max_array_value - min_array_value)\n#         scaled_array.append(scaled_value)\n\n    return scaled_value\n\n# Example usage\narray = attn_imp\nmin_value = 0\nmax_value = 255\n\nscaled_array = scale_array(array, min_value, max_value)\nprint(scaled_array)  # Output: [0.0, 25.0, 50.0, 75.0, 100.0]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:36:12.022851Z","iopub.execute_input":"2024-04-07T08:36:12.023164Z","iopub.status.idle":"2024-04-07T08:36:12.032254Z","shell.execute_reply.started":"2024-04-07T08:36:12.023131Z","shell.execute_reply":"2024-04-07T08:36:12.031586Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"0 255\n0.0 8.013932260901383\n[  9.68326314 197.68982259  40.12985196  12.66820278  68.86362339\n   9.33527945   3.83375762 112.47360991  39.16424706  40.18432026\n  54.18590521  14.13333287  26.16636852  79.30471863  14.07612639\n  82.15585207   2.33640122  75.38474176  10.87797196  83.64628826\n  22.03394664   2.95587944  52.08846202  25.0849615   56.69823381\n   1.26216706  55.66771688  77.37183633  21.70301173 255.\n  74.89097646  47.50146237 101.66596611  86.3920809   55.48171939\n  87.88707411  19.46120371  12.62414612  55.55464479  45.15891845\n  93.08070729   9.13373733   8.76981857 100.63251284  30.86249149\n  12.94030778  10.56541555 173.63062858   9.35418541  38.20066011\n 102.62804108  90.32881544  68.73708077  26.00578948   9.73002099\n  32.48192761  21.69000828  74.13839339 127.43331457   8.83658373\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.        ]\n","output_type":"stream"}]}]}