{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":29869,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport torch.optim as optim\nfrom IPython.core.debugger import set_trace\nfrom collections import Counter\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator, GloVe\nfrom torchtext.data.utils import get_tokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-10T15:56:22.097027Z","iopub.execute_input":"2024-04-10T15:56:22.097295Z","iopub.status.idle":"2024-04-10T15:56:25.290827Z","shell.execute_reply.started":"2024-04-10T15:56:22.097268Z","shell.execute_reply":"2024-04-10T15:56:25.290086Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\n\n# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")\n      \nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T15:56:25.292929Z","iopub.execute_input":"2024-04-10T15:56:25.293239Z","iopub.status.idle":"2024-04-10T15:56:25.368481Z","shell.execute_reply.started":"2024-04-10T15:56:25.293204Z","shell.execute_reply":"2024-04-10T15:56:25.367680Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"GPU is available\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"base_csv = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'\ndf = pd.read_csv(base_csv)\ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-04-10T15:56:27.594688Z","iopub.execute_input":"2024-04-10T15:56:27.594969Z","iopub.status.idle":"2024-04-10T15:56:28.867562Z","shell.execute_reply.started":"2024-04-10T15:56:27.594942Z","shell.execute_reply":"2024-04-10T15:56:28.866822Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Analysing sentiment","metadata":{}},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"stop_words = list(set(stopwords.words('english')))","metadata":{"execution":{"iopub.status.busy":"2024-04-10T15:56:32.006236Z","iopub.execute_input":"2024-04-10T15:56:32.006528Z","iopub.status.idle":"2024-04-10T15:56:32.014783Z","shell.execute_reply.started":"2024-04-10T15:56:32.006501Z","shell.execute_reply":"2024-04-10T15:56:32.013995Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def preprocess_string(s):\n    s = s.lower()\n    s = ' '.join([word for word in s.split() if word not in stop_words])\n    # replace <br /><br /> with nothing\n    s = re.sub('<[^>]+>', '', s)\n    # Remove all non-word characters (everything except numbers and letters)\n    s = re.sub(r\"[^\\w\\s]\", ' ', s)\n    # Replace all runs of whitespaces with no space\n    s = re.sub(r\"\\s+\", ' ', s)\n    # replace digits with no space\n    s = re.sub(r\"\\d\", '', s)\n    \n    # remove single characters\n    s = ' '.join(list(filter(lambda x: len(x)!=1, s.split())))\n    \n\n    return s","metadata":{"execution":{"iopub.status.busy":"2024-04-10T15:56:35.825438Z","iopub.execute_input":"2024-04-10T15:56:35.825769Z","iopub.status.idle":"2024-04-10T15:56:35.833617Z","shell.execute_reply.started":"2024-04-10T15:56:35.825737Z","shell.execute_reply":"2024-04-10T15:56:35.832679Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.loc[:, 'review_2'] = df.loc[:, 'review'].apply(preprocess_string)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T15:56:42.425404Z","iopub.execute_input":"2024-04-10T15:56:42.425693Z","iopub.status.idle":"2024-04-10T15:57:18.540061Z","shell.execute_reply.started":"2024-04-10T15:56:42.425667Z","shell.execute_reply":"2024-04-10T15:57:18.539289Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T15:57:18.542366Z","iopub.execute_input":"2024-04-10T15:57:18.542678Z","iopub.status.idle":"2024-04-10T15:57:18.553119Z","shell.execute_reply.started":"2024-04-10T15:57:18.542641Z","shell.execute_reply":"2024-04-10T15:57:18.552465Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  \\\n0  One of the other reviewers has mentioned that ...  positive   \n1  A wonderful little production. <br /><br />The...  positive   \n2  I thought this was a wonderful way to spend ti...  positive   \n3  Basically there's a family where a little boy ...  negative   \n4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n\n                                            review_2  \n0  one reviewers mentioned watching oz episode ho...  \n1  wonderful little production the filming techni...  \n2  thought wonderful way spend time hot summer we...  \n3  basically there family little boy jake thinks ...  \n4  petter mattei love time money visually stunnin...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>review_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>one reviewers mentioned watching oz episode ho...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>wonderful little production the filming techni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>thought wonderful way spend time hot summer we...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>basically there family little boy jake thinks ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>petter mattei love time money visually stunnin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X,y = df['review_2'].values,df['sentiment'].values\nx_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\nprint(f'shape of train data is {x_train.shape}')\nprint(f'shape of test data is {x_test.shape}')\ny_train = [1 if label =='positive' else 0 for label in y_train]  \ny_test = [1 if label =='positive' else 0 for label in y_test] ","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:03:28.698980Z","iopub.execute_input":"2024-04-10T17:03:28.699306Z","iopub.status.idle":"2024-04-10T17:03:28.795422Z","shell.execute_reply.started":"2024-04-10T17:03:28.699270Z","shell.execute_reply":"2024-04-10T17:03:28.794713Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stdout","text":"shape of train data is (37500,)\nshape of test data is (12500,)\n","output_type":"stream"}]},{"cell_type":"code","source":"embed_dim = 50\nglobe = GloVe(name='6B', dim=embed_dim)\nglove_weights = torch.load(f\".vector_cache/glove.6B.{embed_dim}d.txt.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T15:57:18.656605Z","iopub.execute_input":"2024-04-10T15:57:18.656853Z","iopub.status.idle":"2024-04-10T16:00:31.782551Z","shell.execute_reply.started":"2024-04-10T15:57:18.656825Z","shell.execute_reply":"2024-04-10T16:00:31.781843Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":".vector_cache/glove.6B.zip: 862MB [02:38, 5.43MB/s]                              \n100%|█████████▉| 398592/400000 [00:30<00:00, 27563.75it/s]","output_type":"stream"}]},{"cell_type":"code","source":"glove_vocab = glove_weights[0]\nglove_word_to_id = glove_weights[1]\nglove_vectors = glove_weights[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:01:02.097464Z","iopub.execute_input":"2024-04-10T16:01:02.097753Z","iopub.status.idle":"2024-04-10T16:01:02.101989Z","shell.execute_reply.started":"2024-04-10T16:01:02.097726Z","shell.execute_reply":"2024-04-10T16:01:02.101202Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"complete = ' '.join(df['review_2'].tolist()).split()\nprint(len(complete))\n\n# word_list = []\n\n# stop_words = set(stopwords.words('english')) \n# for sent in x_train:\n#     for word in sent.lower().split():\n#         word = preprocess_string(word)\n#         if word not in stop_words and word != '':\n#             word_list.append(word)\n            \ncounter = Counter(complete)\n\nprint(counter.most_common(10))\n\ncorpus = sorted(counter, key=counter.get, reverse=True)[:2000]\nword_to_id = {word:i+1 for i, word in enumerate(corpus)}\nid_to_word = {i+1:word for i, word in enumerate(corpus)}\n\ntrain_sequences, test_sequences = list(), list()\n\nfor train_sent in x_train:\n    #set_trace()\n    train_sequence = [word_to_id[word] for word in train_sent.split() if word in word_to_id.keys()]\n    train_sequences.append(train_sequence)\n    \nfor test_sent in x_test:\n    test_sequence = [word_to_id[word] for word in test_sent.split() if word in word_to_id.keys()]\n    test_sequences.append(test_sequence)\n    \nlist(map(len, [train_sequences, test_sequences]))","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:03:32.580509Z","iopub.execute_input":"2024-04-10T17:03:32.580902Z","iopub.status.idle":"2024-04-10T17:03:37.418211Z","shell.execute_reply.started":"2024-04-10T17:03:32.580856Z","shell.execute_reply":"2024-04-10T17:03:37.417359Z"},"trusted":true},"execution_count":169,"outputs":[{"name":"stdout","text":"6232887\n[('movie', 87935), ('film', 79675), ('one', 53585), ('like', 40160), ('it', 29982), ('good', 29737), ('the', 28864), ('time', 25099), ('even', 24856), ('would', 24599)]\n","output_type":"stream"},{"execution_count":169,"output_type":"execute_result","data":{"text/plain":"[37500, 12500]"},"metadata":{}}]},{"cell_type":"code","source":"print(len(word_list))","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:49:42.037320Z","iopub.execute_input":"2024-04-10T16:49:42.037717Z","iopub.status.idle":"2024-04-10T16:49:42.043702Z","shell.execute_reply.started":"2024-04-10T16:49:42.037666Z","shell.execute_reply":"2024-04-10T16:49:42.042782Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stdout","text":"4411068\n","output_type":"stream"}]},{"cell_type":"code","source":"size_vocab = 2000\nweight_matrix = np.zeros((size_vocab+1, embed_dim))\n\nfor word, id_ in word_to_id.items():\n    glove_id = glove_word_to_id[word]\n    weight_matrix[id_] = glove_vectors[glove_id\n                                       \nweight_matrix = weight_matrix.astype(np.float32)\nprint(weight_matrix.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:38:36.997045Z","iopub.execute_input":"2024-04-10T16:38:36.997311Z","iopub.status.idle":"2024-04-10T16:38:37.014315Z","shell.execute_reply.started":"2024-04-10T16:38:36.997284Z","shell.execute_reply":"2024-04-10T16:38:37.013487Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"glove_id_to_word = {i:word for i, word in enumerate(glove_vocab)}\nfor integer in train_sequences[0]:\n    print(glove_id_to_word[integer], end= ' ')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T17:49:02.887662Z","iopub.execute_input":"2024-04-09T17:49:02.887985Z","iopub.status.idle":"2024-04-09T17:49:02.982731Z","shell.execute_reply.started":"2024-04-09T17:49:02.887952Z","shell.execute_reply":"2024-04-09T17:49:02.981979Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"thousands movies ve seen far first one made think wasted talents expression never ever seen many fine actors giving dreadful performances frédéric pierrot elsa zylberstein and on aging make up quite awful and make worse lit broadly use music love first sight young aide de camp times could feel spectators around smile awkwardly far antoine de caunes quite good actor seeing one les de aube think start considering quitting please antoine give master project doubt deserve it ","output_type":"stream"}]},{"cell_type":"code","source":"def tockenize(x_train,y_train,x_val,y_val):\n    word_list = []\n\n    stop_words = set(stopwords.words('english')) \n    for sent in x_train:\n        for word in sent.lower().split():\n            word = preprocess_string(word)\n            if word not in stop_words and word != '':\n                word_list.append(word)\n  \n    corpus = Counter(word_list)\n    # sorting on the basis of most common words\n    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:2000]\n    # creating a dict\n    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n    \n    # tockenize\n    final_list_train,final_list_test = [],[]\n    for sent in x_train:\n            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                     if preprocess_string(word) in onehot_dict.keys()])\n    for sent in x_val:\n            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                    if preprocess_string(word) in onehot_dict.keys()])\n            \n    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:56:12.254347Z","iopub.execute_input":"2024-04-09T14:56:12.254638Z","iopub.status.idle":"2024-04-09T14:56:12.344984Z","shell.execute_reply.started":"2024-04-09T14:56:12.254603Z","shell.execute_reply":"2024-04-09T14:56:12.344121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:56:12.346623Z","iopub.execute_input":"2024-04-09T14:56:12.346928Z","iopub.status.idle":"2024-04-09T14:59:23.504111Z","shell.execute_reply.started":"2024-04-09T14:56:12.346892Z","shell.execute_reply":"2024-04-09T14:59:23.503390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analysing review length","metadata":{}},{"cell_type":"code","source":"rev_len = [len(i) for i in x_train]\npd.Series(rev_len).hist()\nplt.show()\npd.Series(rev_len).describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-09T14:59:23.510877Z","iopub.execute_input":"2024-04-09T14:59:23.511217Z","iopub.status.idle":"2024-04-09T14:59:23.742978Z","shell.execute_reply.started":"2024-04-09T14:59:23.511187Z","shell.execute_reply":"2024-04-09T14:59:23.742039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def padding_(sentences, seq_len):\n    features = np.zeros((len(sentences), seq_len),dtype=int)\n    for ii, review in enumerate(sentences):\n        if len(review) != 0:\n            #features[ii, -len(review):] = np.array(review)[:seq_len]\n            features[ii, :len(review)] = np.array(review)[:seq_len]\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:52:29.897792Z","iopub.execute_input":"2024-04-10T16:52:29.898070Z","iopub.status.idle":"2024-04-10T16:52:29.904300Z","shell.execute_reply.started":"2024-04-10T16:52:29.898042Z","shell.execute_reply":"2024-04-10T16:52:29.903380Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"#we have very less number of reviews with length > 500.\n#So we will consideronly those below it.\nx_train_pad = torch.tensor(padding_(train_sequences,200))\nx_test_pad = torch.tensor(padding_(test_sequences,200))\nx_train_pad.shape, x_test_pad.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:03:52.209163Z","iopub.execute_input":"2024-04-10T17:03:52.209447Z","iopub.status.idle":"2024-04-10T17:03:53.265585Z","shell.execute_reply.started":"2024-04-10T17:03:52.209419Z","shell.execute_reply":"2024-04-10T17:03:53.264739Z"},"trusted":true},"execution_count":170,"outputs":[{"execution_count":170,"output_type":"execute_result","data":{"text/plain":"(torch.Size([37500, 200]), torch.Size([12500, 200]))"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"def get_masks(padded):\n    B, T = padded.shape\n    mask = torch.eq(padded, 0).to(torch.float32)\n    mask = mask * -1e9\n    masked_reshape = mask.reshape(B, 1, T)\n    return masked_reshape\n\ntrain_mask = get_masks(x_train_pad)\nval_mask = get_masks(x_test_pad)\nprint(train_mask.shape, val_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:50.329150Z","iopub.execute_input":"2024-04-10T17:07:50.329530Z","iopub.status.idle":"2024-04-10T17:07:50.378916Z","shell.execute_reply.started":"2024-04-10T17:07:50.329491Z","shell.execute_reply":"2024-04-10T17:07:50.377946Z"},"trusted":true},"execution_count":194,"outputs":[{"name":"stdout","text":"torch.Size([37500, 1, 200]) torch.Size([12500, 1, 200])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_angle(timesteps, dim):\n    k = np.arange(dim)[np.newaxis, :]\n    i = k // 2\n\n    positions = np.arange(timesteps)[:, np.newaxis]\n    angles = positions / (10000 ** (2*i/dim))\n\n    return angles\n\ndef get_positional_embeddings(angles):\n    angles[:, 0::2] = np.sin(angles[:, 0::2])\n    angles[:, 1::2] = np.cos(angles[:, 1::2])\n\n    return torch.tensor(angles, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:50.653453Z","iopub.execute_input":"2024-04-10T17:07:50.653721Z","iopub.status.idle":"2024-04-10T17:07:50.661403Z","shell.execute_reply.started":"2024-04-10T17:07:50.653694Z","shell.execute_reply":"2024-04-10T17:07:50.660463Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        #self.embedding_layer = nn.Embedding.from_pretrained(torch.tensor(weight_matrix), freeze=False)\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:50.888636Z","iopub.execute_input":"2024-04-10T17:07:50.888902Z","iopub.status.idle":"2024-04-10T17:07:50.894159Z","shell.execute_reply.started":"2024-04-10T17:07:50.888872Z","shell.execute_reply":"2024-04-10T17:07:50.893460Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        self.softmax = nn.Softmax(dim=-1)\n        \n    def forward(self, x, mask):\n        #set_trace()\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = self.softmax(wei)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:51.569829Z","iopub.execute_input":"2024-04-10T17:07:51.570107Z","iopub.status.idle":"2024-04-10T17:07:51.579255Z","shell.execute_reply.started":"2024-04-10T17:07:51.570080Z","shell.execute_reply":"2024-04-10T17:07:51.578476Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.sa = Head(head_size)\n        self.avgpool = nn.AvgPool1d(timesteps)\n        self.inter1_layer = nn.Linear(head_size, head_size)\n        self.output = nn.Linear(head_size, output)\n        self.dropout = nn.Dropout(0.7)\n        \n    def forward(self, x, mask, positional_encoding):\n        B, T = x.shape \n        #set_trace()\n        embedding = self.embedding(x) + positional_encoding # (B, timesteps, n_embed)\n        embedding = self.dropout(embedding)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size)\n        sa_out = self.dropout(sa_out)\n        averaged = self.avgpool(sa_out.permute(0, 2, 1)) # (B, head_size, 1)\n        inter1 = self.inter1_layer(averaged.view(B, -1)) # (B, head_size) @ (head_size, head_size) --> (B, headsize)\n        inter1 = self.dropout(inter1)\n        output = self.output(inter1) # (B, head_size) @ (head_size, output) --> (B, output)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:52.310448Z","iopub.execute_input":"2024-04-10T17:07:52.310710Z","iopub.status.idle":"2024-04-10T17:07:52.321387Z","shell.execute_reply.started":"2024-04-10T17:07:52.310684Z","shell.execute_reply":"2024-04-10T17:07:52.320552Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, mask, y_batch, positional_encoding):\n    optimizer.zero_grad()\n    output = model(x_batch, mask, positional_encoding)\n    #set_trace()\n    output = nn.Sigmoid()(output)\n    \n    loss = loss_function(output.view(-1), y_batch.view(-1))\n    \n    correct = 0\n    correct += ((output.view(-1) > 0.5).float() == y_batch).float().sum()\n    accuracy = correct / y_batch.shape[0]\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:53.187766Z","iopub.execute_input":"2024-04-10T17:07:53.188034Z","iopub.status.idle":"2024-04-10T17:07:53.195288Z","shell.execute_reply.started":"2024-04-10T17:07:53.188008Z","shell.execute_reply":"2024-04-10T17:07:53.194458Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"n_embed = 50\ntimesteps = x_train_pad.shape[-1]\nbatch_size = 256\nbatch_per_epoch = x_train_pad.shape[0] // batch_size\n\ntrain_padded, train_y = x_train_pad.to(device).long(), torch.tensor(y_train, dtype=torch.float).to(device)\nval_padded, val_y = x_test_pad.to(device).long(), torch.tensor(y_test, dtype=torch.float).to(device) \ntrain_mask, val_mask = train_mask.to(device), val_mask.to(device)\ntrain_positional_encoding = get_positional_embeddings(get_angle(timesteps, n_embed)).to(device)\nval_positional_encoding = get_positional_embeddings(get_angle(val_padded.shape[-1], n_embed)).to(device)\nprint('Shape of encodings are', train_positional_encoding.shape, val_positional_encoding.shape)\n\n\nmodel = Encoder(len(word_to_id)+1, n_embed, timesteps, head_size=n_embed, output=1).to(device)\n\nloss_function = nn.BCELoss()\n#loss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:54.189701Z","iopub.execute_input":"2024-04-10T17:07:54.190030Z","iopub.status.idle":"2024-04-10T17:07:54.239487Z","shell.execute_reply.started":"2024-04-10T17:07:54.189994Z","shell.execute_reply":"2024-04-10T17:07:54.238694Z"},"trusted":true},"execution_count":200,"outputs":[{"name":"stdout","text":"Shape of encodings are torch.Size([200, 50]) torch.Size([200, 50])\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_accuracy(outputs, labels):\n    correct = 0\n    #correct += (torch.argmax(F.softmax(outputs, dim=-1), dim=-1) == labels).float().sum()\n    correct += ((outputs.view(-1) > 0.5).float() == labels).float().sum()\n    return correct / labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:54.852033Z","iopub.execute_input":"2024-04-10T17:07:54.852296Z","iopub.status.idle":"2024-04-10T17:07:54.857775Z","shell.execute_reply.started":"2024-04-10T17:07:54.852269Z","shell.execute_reply":"2024-04-10T17:07:54.856836Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0, 20):\n    train_loss, val_loss = 0, 0\n    training_accuracy = 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = train_padded[start:start+batch_size], train_y[start:start+batch_size], train_mask[start:start+batch_size]\n#         x_batch, y_batch, mask = x_batch.to(device).long(), y_batch.to(device).long(), mask.to(device).long()\n\n        model.train(True)\n    \n        loss, accuracy = train_epoch(x_batch, mask, y_batch, train_positional_encoding)\n        train_loss += loss\n        training_accuracy += accuracy\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')\n    print(f'Accuracy at Epoch {epoch} is {training_accuracy / (batch_per_epoch)}')\n    \n    model.eval()\n    with torch.no_grad():\n        output_val = model(val_padded, val_mask, val_positional_encoding)\n        output_val = nn.Sigmoid()(output_val)\n#         set_trace()\n        \n        loss_val = loss_function(output_val.view(-1), val_y.view(-1))\n        \n        accuracy = calculate_accuracy(output_val, val_y)\n        \n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        print(f'Accuracy at Epoch {epoch} is {accuracy}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:07:56.219961Z","iopub.execute_input":"2024-04-10T17:07:56.220239Z","iopub.status.idle":"2024-04-10T17:08:23.893130Z","shell.execute_reply.started":"2024-04-10T17:07:56.220213Z","shell.execute_reply":"2024-04-10T17:08:23.892421Z"},"trusted":true},"execution_count":202,"outputs":[{"name":"stdout","text":"Epoch 0 Loss: 0.6878106594085693\nAccuracy at Epoch 0 is 0.5407748222351074\nEpoch 0 Val loss: 0.6389999985694885\nAccuracy at Epoch 0 is 0.651919960975647\n\nEpoch 1 Loss: 0.6475483775138855\nAccuracy at Epoch 1 is 0.6189265847206116\nEpoch 1 Val loss: 0.6157950758934021\nAccuracy at Epoch 1 is 0.6887999773025513\n\nEpoch 2 Loss: 0.6148992776870728\nAccuracy at Epoch 2 is 0.6590860486030579\nEpoch 2 Val loss: 0.5796167254447937\nAccuracy at Epoch 2 is 0.7179999947547913\n\nEpoch 3 Loss: 0.5907679200172424\nAccuracy at Epoch 3 is 0.6843963861465454\nEpoch 3 Val loss: 0.566268801689148\nAccuracy at Epoch 3 is 0.7349599599838257\n\nEpoch 4 Loss: 0.5707857012748718\nAccuracy at Epoch 4 is 0.7056131958961487\nEpoch 4 Val loss: 0.5326733589172363\nAccuracy at Epoch 4 is 0.7488799691200256\n\nEpoch 5 Loss: 0.5450180172920227\nAccuracy at Epoch 5 is 0.7226294875144958\nEpoch 5 Val loss: 0.5574970841407776\nAccuracy at Epoch 5 is 0.7542399764060974\n\nEpoch 6 Loss: 0.5312226414680481\nAccuracy at Epoch 6 is 0.7382277250289917\nEpoch 6 Val loss: 0.5276884436607361\nAccuracy at Epoch 6 is 0.764799952507019\n\nEpoch 7 Loss: 0.5153310298919678\nAccuracy at Epoch 7 is 0.7492775917053223\nEpoch 7 Val loss: 0.5143573880195618\nAccuracy at Epoch 7 is 0.7763999700546265\n\nEpoch 8 Loss: 0.49987056851387024\nAccuracy at Epoch 8 is 0.759631872177124\nEpoch 8 Val loss: 0.5201638340950012\nAccuracy at Epoch 8 is 0.775119960308075\n\nEpoch 9 Loss: 0.4903486967086792\nAccuracy at Epoch 9 is 0.7660263180732727\nEpoch 9 Val loss: 0.5087637305259705\nAccuracy at Epoch 9 is 0.7844799757003784\n\nEpoch 10 Loss: 0.47581616044044495\nAccuracy at Epoch 10 is 0.7756849527359009\nEpoch 10 Val loss: 0.4824088215827942\nAccuracy at Epoch 10 is 0.7869600057601929\n\nEpoch 11 Loss: 0.46923092007637024\nAccuracy at Epoch 11 is 0.7817850708961487\nEpoch 11 Val loss: 0.46249666810035706\nAccuracy at Epoch 11 is 0.8004800081253052\n\nEpoch 12 Loss: 0.46304357051849365\nAccuracy at Epoch 12 is 0.7839522361755371\nEpoch 12 Val loss: 0.4655803442001343\nAccuracy at Epoch 12 is 0.8000800013542175\n\nEpoch 13 Loss: 0.456219345331192\nAccuracy at Epoch 13 is 0.7891694903373718\nEpoch 13 Val loss: 0.47463980317115784\nAccuracy at Epoch 13 is 0.7951200008392334\n\nEpoch 14 Loss: 0.4521365761756897\nAccuracy at Epoch 14 is 0.7912296652793884\nEpoch 14 Val loss: 0.46463432908058167\nAccuracy at Epoch 14 is 0.8029599785804749\n\nEpoch 15 Loss: 0.4439055621623993\nAccuracy at Epoch 15 is 0.7949486374855042\nEpoch 15 Val loss: 0.46930262446403503\nAccuracy at Epoch 15 is 0.8035199642181396\n\nEpoch 16 Loss: 0.4371316432952881\nAccuracy at Epoch 16 is 0.802734375\nEpoch 16 Val loss: 0.459332138299942\nAccuracy at Epoch 16 is 0.8048799633979797\n\nEpoch 17 Loss: 0.4354223906993866\nAccuracy at Epoch 17 is 0.8016106486320496\nEpoch 17 Val loss: 0.42411020398139954\nAccuracy at Epoch 17 is 0.8174399733543396\n\nEpoch 18 Loss: 0.42527908086776733\nAccuracy at Epoch 18 is 0.8076037764549255\nEpoch 18 Val loss: 0.46836528182029724\nAccuracy at Epoch 18 is 0.8072800040245056\n\nEpoch 19 Loss: 0.4225090742111206\nAccuracy at Epoch 19 is 0.8125535249710083\nEpoch 19 Val loss: 0.433808833360672\nAccuracy at Epoch 19 is 0.8150399923324585\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"imp = list()\n\ndef hook_function(module, input, output):\n    #set_trace()\n    if not model.training:\n        #set_trace()\n        imp.append(output[0].tolist())","metadata":{"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"#handle.remove()\nfor name, layer in model.named_children():\n    if name == 'sa':\n        for sa_name, sa_layer in layer.named_children():\n            if sa_name == 'softmax':\n                print(sa_name)\n                handle = sa_layer.register_forward_hook(hook_function)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:08:30.898578Z","iopub.execute_input":"2024-04-10T17:08:30.898847Z","iopub.status.idle":"2024-04-10T17:08:30.904552Z","shell.execute_reply.started":"2024-04-10T17:08:30.898819Z","shell.execute_reply":"2024-04-10T17:08:30.903724Z"},"trusted":true},"execution_count":204,"outputs":[{"name":"stdout","text":"softmax\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_text(text):\n    #set_trace()\n    word_seq = np.array([word_to_id[preprocess_string(word)] for word in text.split() \n                     if preprocess_string(word) in word_to_id.keys()])\n    word_seq = np.expand_dims(word_seq,axis=0)\n    pad =  torch.from_numpy(padding_(word_seq,200))\n    inputs = pad.to(device)\n    test_mask = get_masks(inputs).to(device)\n    batch_size = 1\n    model.eval()\n    output = model(inputs, test_mask, train_positional_encoding)\n    output = nn.Sigmoid()(output)\n    return output.item()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:08:58.118732Z","iopub.execute_input":"2024-04-10T17:08:58.119035Z","iopub.status.idle":"2024-04-10T17:08:58.126426Z","shell.execute_reply.started":"2024-04-10T17:08:58.119001Z","shell.execute_reply":"2024-04-10T17:08:58.125603Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"base_df = pd.read_csv(base_csv)\nbase_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-09T15:01:38.581212Z","iopub.execute_input":"2024-04-09T15:01:38.581567Z","iopub.status.idle":"2024-04-09T15:01:39.155978Z","shell.execute_reply.started":"2024-04-09T15:01:38.581533Z","shell.execute_reply":"2024-04-09T15:01:39.155203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T15:13:18.208148Z","iopub.execute_input":"2024-04-09T15:13:18.208514Z","iopub.status.idle":"2024-04-09T15:13:18.220125Z","shell.execute_reply.started":"2024-04-09T15:13:18.208475Z","shell.execute_reply":"2024-04-09T15:13:18.219360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_df.loc[index, 'review']","metadata":{"execution":{"iopub.status.busy":"2024-04-09T15:22:41.829555Z","iopub.execute_input":"2024-04-09T15:22:41.829852Z","iopub.status.idle":"2024-04-09T15:22:41.835113Z","shell.execute_reply.started":"2024-04-09T15:22:41.829823Z","shell.execute_reply":"2024-04-09T15:22:41.834424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for word in df['review'][index].split():\n    w = preprocess_string(word)\n    if word in word_to_id.keys():\n        print(w)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remember to reset the list imp after every test prediction\n# 13000, 14000, 15000, 15100, 33415\nimp = list()\nindex = 15100 \nprint(df['review'][index])\nprint('='*70)\nprint(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\nprint('='*70)\npro = predict_text(df['review'][index])\nstatus = \"positive\" if pro > 0.5 else \"negative\"\npro = (1 - pro) if status == \"negative\" else pro\nprint(f'Predicted sentiment is {status} with a probability of {pro}')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:10:15.617537Z","iopub.execute_input":"2024-04-10T17:10:15.617849Z","iopub.status.idle":"2024-04-10T17:10:15.633185Z","shell.execute_reply.started":"2024-04-10T17:10:15.617816Z","shell.execute_reply":"2024-04-10T17:10:15.632225Z"},"trusted":true},"execution_count":213,"outputs":[{"name":"stdout","text":"I used to have a fascination with the cartoon back in college when it was being made. It had much the charm of \"Get Smart\". While it admittedly had its faults, it was rather enjoyable.<br /><br />Naturally I was very interested in seeing the film version. That was before I saw it. Afterwords I wished it had never been made.<br /><br />Besides being miscast all around (who on Earth though Broderick was even close to the role?) it just didn't make the grade.<br /><br />The effects were reasonable and perhaps the ONLY thing I liked about the movie; seeing a live-action version of the gadgets in action! What was missing was a story and treatment which made it funny or charming or interesting.<br /><br />The original was a wacky cartoon with a very lighthearted attitude. It was FUN. The motion picture became murky and took itself FAR too seriously. If it had seriously had a great plot or went crazy enough to make it seem like a \"cartoon on film\" it might have been enjoyable.<br /><br />As it exists it doesn't deserve to be considered part of the \"Gadget Legacy\".\n======================================================================\nActual sentiment is  : negative\n======================================================================\nPredicted sentiment is positive with a probability of 0.8764303922653198\n","output_type":"stream"}]},{"cell_type":"code","source":"imp","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:09:08.639451Z","iopub.execute_input":"2024-04-10T17:09:08.639753Z","iopub.status.idle":"2024-04-10T17:09:08.645004Z","shell.execute_reply.started":"2024-04-10T17:09:08.639726Z","shell.execute_reply":"2024-04-10T17:09:08.644363Z"},"trusted":true},"execution_count":208,"outputs":[{"execution_count":208,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"attn_imp = np.sum(np.array(imp)[0], axis=0)\ncleaned_words = ' '.join([word for word in df.loc[index, 'review'].split() if preprocess_string(word) in word_to_id.keys()])\n#colors = attn_imp * (255/np.max(attn_imp))\nmaxi = np.max(attn_imp); mini = np.min(attn_imp)\nmax_val, min_val = 250, 0\ncolors = min_val + (max_val - min_val) * (attn_imp - mini) / (maxi - mini)\n\nfor color, word in zip(colors.tolist(), cleaned_words.split()):\n    if int(color) > 0:\n        if int(color) < 30:\n            r, g, b = 255, 255, 255\n            print(f'\\033[48;2;{int(r)};{g};{b}m{word}\\033', end=' ')\n        else:\n            r, g, b = int(color), 0, 0\n            print(f'\\033[48;2;{r};{g};{b}m\\033[1m\\033[97m{word}\\033[0m', end=' ')\n            #print(f'\\033[48;2;{r};{g};{b}m\\033[97m{word}\\033[0m', end=' ')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:10:21.968641Z","iopub.execute_input":"2024-04-10T17:10:21.968912Z","iopub.status.idle":"2024-04-10T17:10:21.990315Z","shell.execute_reply.started":"2024-04-10T17:10:21.968886Z","shell.execute_reply":"2024-04-10T17:10:21.989590Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"\u001b[48;2;255;255;255mused\u001b \u001b[48;2;255;255;255mcartoon\u001b \u001b[48;2;39;0;0m\u001b[1m\u001b[97mback\u001b[0m \u001b[48;2;255;255;255mcollege\u001b \u001b[48;2;255;255;255mmuch\u001b \u001b[48;2;36;0;0m\u001b[1m\u001b[97mcharm\u001b[0m \u001b[48;2;255;255;255m\"Get\u001b \u001b[48;2;255;255;255mSmart\".\u001b \u001b[48;2;255;255;255mrather\u001b \u001b[48;2;255;255;255m/>Naturally\u001b \u001b[48;2;255;255;255minterested\u001b \u001b[48;2;255;255;255mseeing\u001b \u001b[48;2;255;255;255mfilm\u001b \u001b[48;2;255;255;255mversion.\u001b \u001b[48;2;255;255;255msaw\u001b \u001b[48;2;255;255;255maround\u001b \u001b[48;2;255;255;255m(who\u001b \u001b[48;2;255;255;255mEarth\u001b \u001b[48;2;255;255;255mthough\u001b \u001b[48;2;255;255;255meven\u001b \u001b[48;2;255;255;255mrole?)\u001b \u001b[48;2;255;255;255mmake\u001b \u001b[48;2;255;255;255m/>The\u001b \u001b[48;2;255;255;255meffects\u001b \u001b[48;2;255;255;255mperhaps\u001b \u001b[48;2;255;255;255mthing\u001b \u001b[48;2;255;255;255mliked\u001b \u001b[48;2;255;255;255mseeing\u001b \u001b[48;2;255;255;255mversion\u001b \u001b[48;2;255;255;255mmissing\u001b \u001b[48;2;255;255;255mfunny\u001b \u001b[48;2;255;255;255mcharming\u001b \u001b[48;2;255;255;255m/>The\u001b \u001b[48;2;255;255;255mcartoon\u001b \u001b[48;2;255;255;255mattitude.\u001b \u001b[48;2;41;0;0m\u001b[1m\u001b[97mFUN.\u001b[0m \u001b[48;2;117;0;0m\u001b[1m\u001b[97mmotion\u001b[0m \u001b[48;2;35;0;0m\u001b[1m\u001b[97mbecame\u001b[0m \u001b[48;2;255;255;255mtook\u001b \u001b[48;2;255;255;255mFAR\u001b \u001b[48;2;255;255;255mseriously.\u001b \u001b[48;2;255;255;255mseriously\u001b \u001b[48;2;250;0;0m\u001b[1m\u001b[97mgreat\u001b[0m \u001b[48;2;255;255;255mplot\u001b \u001b[48;2;30;0;0m\u001b[1m\u001b[97mcrazy\u001b[0m \u001b[48;2;78;0;0m\u001b[1m\u001b[97menough\u001b[0m \u001b[48;2;255;255;255mmake\u001b \u001b[48;2;255;255;255mseem\u001b \u001b[48;2;255;255;255mlike\u001b \u001b[48;2;255;255;255m\"cartoon\u001b \u001b[48;2;255;255;255mfilm\"\u001b \u001b[48;2;255;255;255mmight\u001b \u001b[48;2;255;255;255m/>As\u001b \u001b[48;2;255;255;255mdeserve\u001b \u001b[48;2;255;255;255mconsidered\u001b \u001b[48;2;255;255;255mpart\u001b ","output_type":"stream"}]},{"cell_type":"code","source":"for r in list(range(160, 255, 5)):\n    #print(f'\\033[48;5;{r};1;1mthis\\033')\n    #print(f'\\033[48;5;{r}mthis\\033')\n    gb = 40\n    print(f'\\033[48;2;{r};{gb};{gb}mthis {r}\\033')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T17:10:32.719945Z","iopub.execute_input":"2024-04-10T17:10:32.720238Z","iopub.status.idle":"2024-04-10T17:10:32.726091Z","shell.execute_reply.started":"2024-04-10T17:10:32.720207Z","shell.execute_reply":"2024-04-10T17:10:32.725298Z"},"trusted":true},"execution_count":215,"outputs":[{"name":"stdout","text":"\u001b[48;2;160;40;40mthis 160\u001b\n\u001b[48;2;165;40;40mthis 165\u001b\n\u001b[48;2;170;40;40mthis 170\u001b\n\u001b[48;2;175;40;40mthis 175\u001b\n\u001b[48;2;180;40;40mthis 180\u001b\n\u001b[48;2;185;40;40mthis 185\u001b\n\u001b[48;2;190;40;40mthis 190\u001b\n\u001b[48;2;195;40;40mthis 195\u001b\n\u001b[48;2;200;40;40mthis 200\u001b\n\u001b[48;2;205;40;40mthis 205\u001b\n\u001b[48;2;210;40;40mthis 210\u001b\n\u001b[48;2;215;40;40mthis 215\u001b\n\u001b[48;2;220;40;40mthis 220\u001b\n\u001b[48;2;225;40;40mthis 225\u001b\n\u001b[48;2;230;40;40mthis 230\u001b\n\u001b[48;2;235;40;40mthis 235\u001b\n\u001b[48;2;240;40;40mthis 240\u001b\n\u001b[48;2;245;40;40mthis 245\u001b\n\u001b[48;2;250;40;40mthis 250\u001b\n","output_type":"stream"}]}]}