{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":29869,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport torch.optim as optim\nfrom IPython.core.debugger import set_trace\nfrom collections import Counter\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.data.utils import get_tokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T06:25:18.987705Z","iopub.execute_input":"2024-04-07T06:25:18.987984Z","iopub.status.idle":"2024-04-07T06:25:18.995903Z","shell.execute_reply.started":"2024-04-07T06:25:18.987957Z","shell.execute_reply":"2024-04-07T06:25:18.995107Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\n\n# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")\n      \nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:23:53.467389Z","iopub.execute_input":"2024-04-07T06:23:53.467702Z","iopub.status.idle":"2024-04-07T06:23:53.539365Z","shell.execute_reply.started":"2024-04-07T06:23:53.467666Z","shell.execute_reply":"2024-04-07T06:23:53.538651Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"GPU is available\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"base_csv = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'\ndf = pd.read_csv(base_csv)\ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-04-07T06:23:53.540802Z","iopub.execute_input":"2024-04-07T06:23:53.541092Z","iopub.status.idle":"2024-04-07T06:23:54.686458Z","shell.execute_reply.started":"2024-04-07T06:23:53.541057Z","shell.execute_reply":"2024-04-07T06:23:54.685562Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Analysing sentiment","metadata":{}},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"stop_words = list(set(stopwords.words('english')))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:25:23.753089Z","iopub.execute_input":"2024-04-07T06:25:23.753368Z","iopub.status.idle":"2024-04-07T06:25:23.757861Z","shell.execute_reply.started":"2024-04-07T06:25:23.753340Z","shell.execute_reply":"2024-04-07T06:25:23.757075Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def preprocess_string(s):\n    s = s.lower()\n    s = ' '.join([word for word in s.split() if word not in stop_words])\n    # replace <br /><br /> with nothing\n    s = re.sub('<[^>]+>', '', s)\n    # Remove all non-word characters (everything except numbers and letters)\n    s = re.sub(r\"[^\\w\\s]\", ' ', s)\n    # Replace all runs of whitespaces with no space\n    s = re.sub(r\"\\s+\", ' ', s)\n    # replace digits with no space\n    s = re.sub(r\"\\d\", '', s)\n    \n    # remove single characters\n    s = ' '.join(list(filter(lambda x: len(x)!=1, s.split())))\n    \n\n    return s","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:25:38.533548Z","iopub.execute_input":"2024-04-07T06:25:38.533845Z","iopub.status.idle":"2024-04-07T06:25:38.541312Z","shell.execute_reply.started":"2024-04-07T06:25:38.533812Z","shell.execute_reply":"2024-04-07T06:25:38.540596Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df.loc[:, 'review'] = df.loc[:, 'review'].apply(preprocess_string)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:25:41.563249Z","iopub.execute_input":"2024-04-07T06:25:41.563548Z","iopub.status.idle":"2024-04-07T06:26:06.229282Z","shell.execute_reply.started":"2024-04-07T06:25:41.563506Z","shell.execute_reply":"2024-04-07T06:26:06.228611Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:00.143695Z","iopub.execute_input":"2024-04-07T06:28:00.143979Z","iopub.status.idle":"2024-04-07T06:28:00.153259Z","shell.execute_reply.started":"2024-04-07T06:28:00.143952Z","shell.execute_reply":"2024-04-07T06:28:00.152635Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  one reviewers mentioned watching oz episode ho...  positive\n1  wonderful little production filming technique ...  positive\n2  thought wonderful way spend time hot summer we...  positive\n3  basically family little boy jake thinks zombie...  negative\n4  petter mattei love time money visually stunnin...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewers mentioned watching oz episode ho...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production filming technique ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically family little boy jake thinks zombie...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei love time money visually stunnin...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"complete = ' '.join(df['review'].tolist()).split()\ncounter = Counter(complete)\n# words like could, would could be removed.\nmost_occur = counter.most_common(4)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:06.063481Z","iopub.execute_input":"2024-04-07T06:28:06.063799Z","iopub.status.idle":"2024-04-07T06:28:07.841548Z","shell.execute_reply.started":"2024-04-07T06:28:06.063765Z","shell.execute_reply":"2024-04-07T06:28:07.840787Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"counter.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:15.103644Z","iopub.execute_input":"2024-04-07T06:28:15.103946Z","iopub.status.idle":"2024-04-07T06:28:15.139971Z","shell.execute_reply.started":"2024-04-07T06:28:15.103913Z","shell.execute_reply":"2024-04-07T06:28:15.139312Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[('movie', 87935),\n ('film', 79675),\n ('one', 53585),\n ('like', 40160),\n ('good', 29737),\n ('time', 25099),\n ('even', 24856),\n ('would', 24599),\n ('story', 23108),\n ('really', 23089)]"},"metadata":{}}]},{"cell_type":"code","source":"X,y = df['review'].values,df['sentiment'].values\nx_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\nprint(f'shape of train data is {x_train.shape}')\nprint(f'shape of test data is {x_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:19.227995Z","iopub.execute_input":"2024-04-07T06:28:19.228264Z","iopub.status.idle":"2024-04-07T06:28:19.320532Z","shell.execute_reply.started":"2024-04-07T06:28:19.228237Z","shell.execute_reply":"2024-04-07T06:28:19.319661Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"shape of train data is (37500,)\nshape of test data is (12500,)\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:24:59.063136Z","iopub.execute_input":"2024-04-07T06:24:59.063423Z","iopub.status.idle":"2024-04-07T06:24:59.068464Z","shell.execute_reply.started":"2024-04-07T06:24:59.063391Z","shell.execute_reply":"2024-04-07T06:24:59.067602Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'ohhh man talking about far bad cheesy horror flicks go movie truly class own real gem first off film originally english that okay voice dubbing truly exceptional favorite excerpt dialog and plenty came from feeling little better thirsty blood and drama play play recap interaction military scientists scene scientist you can it ll disaster military officer that science fiction he proceeds cause complete disaster like scientist predicted scene scientist if many people die military officer you know talking about he many people die scene scientist don it ll kill everyone military officer that nonsense he proceeds kill everyone scene you get idea if enough scenes really stood instant classics one scene military literally guys pointing guns two unarmed men leader yells go get em army guys one time drop guns fist fight two adversaries instant classic and worry attention detail left out movie even hip upbeat keyboard synth soundtrack set mood and trust realize review might contain spoilers many goodies epic really scratched surface movie caliber comes decade true movie watching experience masterpiece wow'"},"metadata":{}}]},{"cell_type":"code","source":"def tockenize(x_train,y_train,x_val,y_val):\n    word_list = []\n\n    stop_words = set(stopwords.words('english')) \n    for sent in x_train:\n        for word in sent.lower().split():\n            word = preprocess_string(word)\n            if word not in stop_words and word != '':\n                word_list.append(word)\n  \n    corpus = Counter(word_list)\n    # sorting on the basis of most common words\n    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n    # creating a dict\n    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n    \n    # tockenize\n    final_list_train,final_list_test = [],[]\n    for sent in x_train:\n            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                     if preprocess_string(word) in onehot_dict.keys()])\n    for sent in x_val:\n            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n                                    if preprocess_string(word) in onehot_dict.keys()])\n            \n    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:21.742659Z","iopub.execute_input":"2024-04-07T06:28:21.742940Z","iopub.status.idle":"2024-04-07T06:28:21.756196Z","shell.execute_reply.started":"2024-04-07T06:28:21.742913Z","shell.execute_reply":"2024-04-07T06:28:21.755430Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:28:24.343597Z","iopub.execute_input":"2024-04-07T06:28:24.343882Z","iopub.status.idle":"2024-04-07T06:31:25.714753Z","shell.execute_reply.started":"2024-04-07T06:28:24.343854Z","shell.execute_reply":"2024-04-07T06:31:25.713976Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(f'Length of vocabulary is {len(vocab)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:31:52.228065Z","iopub.execute_input":"2024-04-07T06:31:52.228369Z","iopub.status.idle":"2024-04-07T06:31:52.232239Z","shell.execute_reply.started":"2024-04-07T06:31:52.228330Z","shell.execute_reply":"2024-04-07T06:31:52.231485Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Length of vocabulary is 1000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Analysing review length","metadata":{}},{"cell_type":"code","source":"rev_len = [len(i) for i in x_train]\npd.Series(rev_len).hist()\nplt.show()\npd.Series(rev_len).describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:31:54.833024Z","iopub.execute_input":"2024-04-07T06:31:54.833287Z","iopub.status.idle":"2024-04-07T06:31:55.055044Z","shell.execute_reply.started":"2024-04-07T06:31:54.833262Z","shell.execute_reply":"2024-04-07T06:31:55.054244Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"count    37500.000000\nmean        67.457253\nstd         46.671170\nmin          2.000000\n25%         38.000000\n50%         53.000000\n75%         82.000000\nmax        619.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"def padding_(sentences, seq_len):\n    features = np.zeros((len(sentences), seq_len),dtype=int)\n    for ii, review in enumerate(sentences):\n        if len(review) != 0:\n            #features[ii, -len(review):] = np.array(review)[:seq_len]\n            features[ii, :len(review)] = np.array(review)[:seq_len]\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:00.802559Z","iopub.execute_input":"2024-04-07T06:32:00.802834Z","iopub.status.idle":"2024-04-07T06:32:00.809203Z","shell.execute_reply.started":"2024-04-07T06:32:00.802808Z","shell.execute_reply":"2024-04-07T06:32:00.808475Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#we have very less number of reviews with length > 500.\n#So we will consideronly those below it.\nx_train_pad = torch.tensor(padding_(x_train,100))\nx_test_pad = torch.tensor(padding_(x_test,100))\nx_train_pad.shape, x_test_pad.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:02.631859Z","iopub.execute_input":"2024-04-07T06:32:02.632162Z","iopub.status.idle":"2024-04-07T06:32:03.491044Z","shell.execute_reply.started":"2024-04-07T06:32:02.632129Z","shell.execute_reply":"2024-04-07T06:32:03.490343Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(torch.Size([37500, 100]), torch.Size([12500, 100]))"},"metadata":{}}]},{"cell_type":"code","source":"x_train_pad[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:06.183202Z","iopub.execute_input":"2024-04-07T06:32:06.183509Z","iopub.status.idle":"2024-04-07T06:32:06.202122Z","shell.execute_reply.started":"2024-04-07T06:32:06.183475Z","shell.execute_reply":"2024-04-07T06:32:06.201492Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"tensor([132, 177,   2, 285, 226,  87, 556, 385, 522, 203, 293, 890,  32, 279,\n         20, 558,  29,  11, 356,  38,  16, 905,  19,  79,  19,  11, 476, 830,\n         41,  21,  80, 379,  41, 476, 346,  83, 242, 545,  55, 107,  93,   5,\n        108, 153, 826, 265,  55,   7, 505, 242,  73, 844, 111, 428,  49, 214,\n         32, 174, 156,   4,  21, 145, 204, 108,  72,  80,   3, 428,  48, 772,\n         64, 407, 514, 104, 830, 809,  87, 282, 356, 251, 295, 243, 348,   5,\n         56,   4,  39,  23, 284,  90,  46,  90,  14,  79,   2,  13, 192, 179,\n         33, 291])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"def get_masks(padded):\n    B, T = padded.shape\n    mask = torch.eq(padded, 0).to(torch.float32)\n    mask = mask * -1e9\n    masked_reshape = mask.reshape(B, 1, T)\n    return masked_reshape\n\ntrain_mask = get_masks(x_train_pad)\nval_mask = get_masks(x_test_pad)\nprint(train_mask.shape, val_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:12.017796Z","iopub.execute_input":"2024-04-07T06:32:12.018217Z","iopub.status.idle":"2024-04-07T06:32:12.050221Z","shell.execute_reply.started":"2024-04-07T06:32:12.018179Z","shell.execute_reply":"2024-04-07T06:32:12.049288Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"torch.Size([37500, 1, 100]) torch.Size([12500, 1, 100])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_angle(timesteps, dim):\n    k = np.arange(dim)[np.newaxis, :]\n    i = k // 2\n\n    positions = np.arange(timesteps)[:, np.newaxis]\n    angles = positions / (10000 ** (2*i/dim))\n\n    return angles\n\ndef get_positional_embeddings(angles):\n    angles[:, 0::2] = np.sin(angles[:, 0::2])\n    angles[:, 1::2] = np.cos(angles[:, 1::2])\n\n    return torch.tensor(angles, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:12.297587Z","iopub.execute_input":"2024-04-07T06:32:12.297858Z","iopub.status.idle":"2024-04-07T06:32:12.305675Z","shell.execute_reply.started":"2024-04-07T06:32:12.297832Z","shell.execute_reply":"2024-04-07T06:32:12.304718Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:13.023645Z","iopub.execute_input":"2024-04-07T06:32:13.023943Z","iopub.status.idle":"2024-04-07T06:32:13.029615Z","shell.execute_reply.started":"2024-04-07T06:32:13.023914Z","shell.execute_reply":"2024-04-07T06:32:13.028656Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        self.softmax = nn.Softmax(dim=-1)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = self.softmax(wei)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:13.031413Z","iopub.execute_input":"2024-04-07T06:32:13.031762Z","iopub.status.idle":"2024-04-07T06:32:13.041426Z","shell.execute_reply.started":"2024-04-07T06:32:13.031728Z","shell.execute_reply":"2024-04-07T06:32:13.040739Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.sa = Head(head_size)\n        self.inter1_layer = nn.Linear(head_size, timesteps)\n        self.output = nn.Linear(timesteps**2, output)\n        \n    def forward(self, x, mask, positional_encoding):\n        B, T = x.shape # validation shape --> (1000, 73)\n#         print(self.embedding(x).shape, positional_encoding.shape)\n        set_trace()\n        embedding = self.embedding(x) + positional_encoding # (B, timesteps, n_embed)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size)\n        # implement average pooling after sa_out\n        inter1 = self.inter1_layer(sa_out) # (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\n        output = self.output(inter1.view(B, -1)) # remove this inter1.view(B, -1) step. now inter1 is (B, 10000)\n#         output = F.softmax(output, dim=-1)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:55.452986Z","iopub.execute_input":"2024-04-07T07:17:55.453284Z","iopub.status.idle":"2024-04-07T07:17:55.462192Z","shell.execute_reply.started":"2024-04-07T07:17:55.453252Z","shell.execute_reply":"2024-04-07T07:17:55.461253Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, mask, y_batch, positional_encoding):\n    optimizer.zero_grad()\n    output = model(x_batch, mask, positional_encoding)\n    #set_trace()\n    output = nn.Sigmoid()(output)\n    \n    \n    loss = loss_function(output.view(-1), y_batch.view(-1))\n    \n    correct = 0\n    correct += ((output.view(-1) > 0.5).float() == y_batch).float().sum()\n    accuracy = correct / y_batch.shape[0]\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:24:27.532787Z","iopub.execute_input":"2024-04-07T07:24:27.533080Z","iopub.status.idle":"2024-04-07T07:24:27.540386Z","shell.execute_reply.started":"2024-04-07T07:24:27.533052Z","shell.execute_reply":"2024-04-07T07:24:27.539669Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"n_embed = 32\ntimesteps = x_train_pad.shape[-1]\nbatch_size = 256\nbatch_per_epoch = x_train_pad.shape[0] // batch_size\n\ntrain_padded, train_y = x_train_pad.to(device).long(), torch.tensor(y_train, dtype=torch.float).to(device)\nval_padded, val_y = x_test_pad.to(device).long(), torch.tensor(y_test, dtype=torch.float).to(device) \ntrain_mask, val_mask = train_mask.to(device), val_mask.to(device)\ntrain_positional_encoding = get_positional_embeddings(get_angle(timesteps, n_embed)).to(device)\nval_positional_encoding = get_positional_embeddings(get_angle(val_padded.shape[-1], n_embed)).to(device)\nprint('Shape of encodings are', train_positional_encoding.shape, val_positional_encoding.shape)\n\n\nmodel = Encoder(len(vocab)+1, n_embed, timesteps, head_size=n_embed, output=1).to(device)\n\nloss_function = nn.BCELoss()\n#loss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n\n#model = nn.DataParallel(model, list(range(torch.cuda.device_count())))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:25:06.852752Z","iopub.execute_input":"2024-04-07T07:25:06.853030Z","iopub.status.idle":"2024-04-07T07:25:06.879187Z","shell.execute_reply.started":"2024-04-07T07:25:06.853002Z","shell.execute_reply":"2024-04-07T07:25:06.878635Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Shape of encodings are torch.Size([100, 32]) torch.Size([100, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_accuracy(outputs, labels):\n    correct = 0\n    #correct += (torch.argmax(F.softmax(outputs, dim=-1), dim=-1) == labels).float().sum()\n    correct += ((outputs.view(-1) > 0.5).float() == labels).float().sum()\n    return correct / labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:18.043026Z","iopub.execute_input":"2024-04-07T06:32:18.043251Z","iopub.status.idle":"2024-04-07T06:32:18.048095Z","shell.execute_reply.started":"2024-04-07T06:32:18.043226Z","shell.execute_reply":"2024-04-07T06:32:18.047233Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0, 5):\n    train_loss, val_loss = 0, 0\n    training_accuracy = 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = train_padded[start:start+batch_size], train_y[start:start+batch_size], train_mask[start:start+batch_size]\n#         x_batch, y_batch, mask = x_batch.to(device).long(), y_batch.to(device).long(), mask.to(device).long()\n\n        model.train(True)\n    \n        loss, accuracy = train_epoch(x_batch, mask, y_batch, train_positional_encoding)\n        train_loss += loss\n        training_accuracy += accuracy\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')\n    print(f'Accuracy at Epoch {epoch} is {training_accuracy / (batch_per_epoch)}')\n    \n    model.eval()\n    with torch.no_grad():\n        output_val = model(val_padded, val_mask, val_positional_encoding)\n        output_val = nn.Sigmoid()(output_val)\n        \n        loss_val = loss_function(output_val.view(-1), val_y.view(-1))\n        \n        accuracy = calculate_accuracy(output_val, val_y)\n        \n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        print(f'Accuracy at Epoch {epoch} is {accuracy}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:25:09.372568Z","iopub.execute_input":"2024-04-07T07:25:09.372837Z","iopub.status.idle":"2024-04-07T07:33:56.885740Z","shell.execute_reply.started":"2024-04-07T07:25:09.372812Z","shell.execute_reply":"2024-04-07T07:33:56.884449Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"> \u001b[0;32m<ipython-input-61-89f39e5e4005>\u001b[0m(13)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n\u001b[0;32m     11 \u001b[0;31m\u001b[0;31m#         print(self.embedding(x).shape, positional_encoding.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m---> 13 \u001b[0;31m        \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositional_encoding\u001b[0m \u001b[0;31m# (B, timesteps, n_embed) # validation: (1000, 73, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0msa_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) # validation: (1000, 73, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15 \u001b[0;31m        \u001b[0minter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter1_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  n\n"},{"name":"stdout","text":"> \u001b[0;32m<ipython-input-61-89f39e5e4005>\u001b[0m(14)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n\u001b[0;32m     12 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositional_encoding\u001b[0m \u001b[0;31m# (B, timesteps, n_embed) # validation: (1000, 73, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m        \u001b[0msa_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) # validation: (1000, 73, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15 \u001b[0;31m        \u001b[0minter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter1_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  embedding.shape\n"},{"name":"stdout","text":"torch.Size([256, 100, 32])\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  n\n"},{"name":"stdout","text":"> \u001b[0;32m<ipython-input-61-89f39e5e4005>\u001b[0m(15)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n\u001b[0;32m     13 \u001b[0;31m        \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositional_encoding\u001b[0m \u001b[0;31m# (B, timesteps, n_embed) # validation: (1000, 73, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0msa_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) # validation: (1000, 73, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m        \u001b[0minter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter1_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17 \u001b[0;31m\u001b[0;31m#         output = F.softmax(output, dim=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  sa_out.shape\n"},{"name":"stdout","text":"torch.Size([256, 100, 32])\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  nn.AvgPool1d(100)(sa_out).shape\n"},{"name":"stdout","text":"*** RuntimeError: Given input size: (100x1x32). Calculated output size: (100x1x0). Output size is too small\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  nn.AvgPool1d(100)(sa_out.permute(0, 2, 1)).shape\n"},{"name":"stdout","text":"torch.Size([256, 32, 1])\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  sa_out.permute(0, 2, 1).shape\n"},{"name":"stdout","text":"torch.Size([256, 32, 100])\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  exit\n"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-446323863abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_positional_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-65-6892a8ee53ce>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(x_batch, mask, y_batch, positional_encoding)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositional_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositional_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-61-89f39e5e4005>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, positional_encoding)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositional_encoding\u001b[0m \u001b[0;31m# (B, timesteps, n_embed) # validation: (1000, 73, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msa_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) # validation: (1000, 73, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0minter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter1_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#         output = F.softmax(output, dim=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-61-89f39e5e4005>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask, positional_encoding)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositional_encoding\u001b[0m \u001b[0;31m# (B, timesteps, n_embed) # validation: (1000, 73, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msa_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) # validation: (1000, 73, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0minter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter1_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#         output = F.softmax(output, dim=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBdbQuit\u001b[0m: "],"ename":"BdbQuit","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"imp = list()\n\ndef hook_function(module, input, output):\n    #set_trace()\n    if not model.training:\n        #set_trace()\n        imp.append(output[0].tolist())","metadata":{"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"handle.remove()\nfor name, layer in model.named_children():\n    if name == 'sa':\n        for sa_name, sa_layer in layer.named_children():\n            if sa_name == 'softmax':\n                print(sa_name)\n                handle = sa_layer.register_forward_hook(hook_function)","metadata":{"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def predict_text(text):\n    #set_trace()\n    word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n                     if preprocess_string(word) in vocab.keys()])\n    word_seq = np.expand_dims(word_seq,axis=0)\n    pad =  torch.from_numpy(padding_(word_seq,100))\n    inputs = pad.to(device)\n    test_mask = get_masks(inputs).to(device)\n    batch_size = 1\n    model.eval()\n    output = model(inputs, test_mask, train_positional_encoding)\n    output = nn.Sigmoid()(output)\n    return output.item()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:32:41.947559Z","iopub.execute_input":"2024-04-07T06:32:41.947853Z","iopub.status.idle":"2024-04-07T06:32:41.955305Z","shell.execute_reply.started":"2024-04-07T06:32:41.947825Z","shell.execute_reply":"2024-04-07T06:32:41.954503Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# 13000, 14000, 15000\nindex = 13000 \nprint(df['review'][index])\nprint('='*70)\nprint(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\nprint('='*70)\npro = predict_text(df['review'][index])\nstatus = \"positive\" if pro > 0.5 else \"negative\"\npro = (1 - pro) if status == \"negative\" else pro\nprint(f'Predicted sentiment is {status} with a probability of {pro}')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:34:08.647748Z","iopub.execute_input":"2024-04-07T06:34:08.648016Z","iopub.status.idle":"2024-04-07T06:34:08.660259Z","shell.execute_reply.started":"2024-04-07T06:34:08.647990Z","shell.execute_reply":"2024-04-07T06:34:08.659374Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"horrible acting worst special ever bore witness bad enough wasted watch crummy pile crap hour half time lost could anything else like getting root canal volunteering jury duty getting drunk even help video put bluntly sincerely believe actually lost iq points course watching idiotic piece mind numbing work perhaps followed advice time never expect decent film written directed produced person never ever expect anything value jeff fahey\n======================================================================\nActual sentiment is  : negative\n======================================================================\nPredicted sentiment is negative with a probability of 0.999410905467812\n","output_type":"stream"}]},{"cell_type":"code","source":"attn_imp = np.sum(np.array(imp)[0], axis=0)\ncleaned_words = ' '.join([word for word in df.loc[index, 'review'].split() if preprocess_string(word) in vocab.keys()])\ncolors = attn_imp * (255/np.max(attn_imp))\n\nfor color, word in zip(colors.tolist(), cleaned_words.split()):\n    if int(color) > 0:\n        if int(color) < 30:\n            r, g, b = 255, 255, 255\n            print(f'\\033[48;2;{int(r)};{g};{b}m{word}\\033', end=' ')\n        else:\n            r, g, b = int(color), 50, 50\n            print(f'\\033[48;2;{r};{g};{b}m{word}\\033', end=' ')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:34:12.453158Z","iopub.execute_input":"2024-04-07T06:34:12.453455Z","iopub.status.idle":"2024-04-07T06:34:12.467565Z","shell.execute_reply.started":"2024-04-07T06:34:12.453422Z","shell.execute_reply":"2024-04-07T06:34:12.466699Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"\u001b[48;2;31;50;50mhorrible\u001b \u001b[48;2;63;50;50macting\u001b \u001b[48;2;255;50;50mworst\u001b \u001b[48;2;255;255;255mspecial\u001b \u001b[48;2;255;255;255mever\u001b \u001b[48;2;31;50;50mbad\u001b \u001b[48;2;41;50;50menough\u001b \u001b[48;2;255;255;255mwasted\u001b \u001b[48;2;255;255;255mwatch\u001b \u001b[48;2;76;50;50mcrap\u001b \u001b[48;2;54;50;50mhour\u001b \u001b[48;2;255;255;255mhalf\u001b \u001b[48;2;255;255;255mtime\u001b \u001b[48;2;255;255;255mlost\u001b \u001b[48;2;57;50;50mcould\u001b \u001b[48;2;255;255;255manything\u001b \u001b[48;2;53;50;50melse\u001b \u001b[48;2;255;255;255mlike\u001b \u001b[48;2;255;255;255mgetting\u001b \u001b[48;2;255;255;255mgetting\u001b \u001b[48;2;38;50;50meven\u001b \u001b[48;2;255;255;255mhelp\u001b \u001b[48;2;255;255;255mvideo\u001b \u001b[48;2;255;255;255mput\u001b \u001b[48;2;31;50;50mbelieve\u001b \u001b[48;2;255;255;255mactually\u001b \u001b[48;2;255;255;255mlost\u001b \u001b[48;2;255;255;255mpoints\u001b \u001b[48;2;255;255;255mcourse\u001b \u001b[48;2;255;255;255mwatching\u001b \u001b[48;2;31;50;50mpiece\u001b \u001b[48;2;255;255;255mmind\u001b \u001b[48;2;255;255;255mwork\u001b \u001b[48;2;255;255;255mperhaps\u001b \u001b[48;2;255;255;255mtime\u001b \u001b[48;2;255;255;255mnever\u001b \u001b[48;2;255;255;255mexpect\u001b \u001b[48;2;255;255;255mdecent\u001b \u001b[48;2;255;255;255mfilm\u001b \u001b[48;2;255;255;255mwritten\u001b \u001b[48;2;255;255;255mdirected\u001b \u001b[48;2;255;255;255mproduced\u001b \u001b[48;2;255;255;255mperson\u001b \u001b[48;2;255;255;255mnever\u001b \u001b[48;2;255;255;255mever\u001b \u001b[48;2;255;255;255mexpect\u001b \u001b[48;2;255;255;255manything\u001b \u001b[48;2;39;50;50mvalue\u001b ","output_type":"stream"}]},{"cell_type":"code","source":"for r in list(range(100, 200, 10)):\n    #print(f'\\033[48;5;{r};1;1mthis\\033')\n    #print(f'\\033[48;5;{r}mthis\\033')\n    print(f'\\033[48;2;{r};10;10mthis\\033')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T18:40:21.637070Z","iopub.status.idle":"2024-04-05T18:40:21.637524Z"},"trusted":true},"execution_count":null,"outputs":[]}]}